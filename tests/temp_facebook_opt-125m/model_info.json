{
  "framework": "vllm",
  "model_name": "facebook/opt-125m",
  "model_type": "vLLM",
  "parameters": "N/A",
  "input_info": {
    "type": "text_or_sampling_params",
    "sample_input": "{'prompts': ['Hello, my name is', 'The president of the United States is', 'The capital of France is', 'The future of AI is'], 'params': {'temperature': 0.0, 'max_tokens': 3}}"
  },
  "output_info": {
    "type": "generated_text",
    "sample_output": "[' J.C', ' not a racist', ' the capital of', ' in the hands']",
    "num_outputs": 4
  },
  "layers": [
    {
      "iter": 0,
      "ops_idx": 0,
      "module_name": "model.decoder.embed_tokens",
      "operator_name": "VocabParallelEmbedding",
      "input_shapes": [
        [
          26
        ]
      ],
      "input_dtypes": [
        "torch.int32"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.117528037,
      "end_timestamp": 3093821.11764814,
      "duration_time": 0.0001201028935611248,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 79976.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0009570216970922533
    },
    {
      "iter": 0,
      "ops_idx": 1,
      "module_name": "lm_head",
      "operator_name": "VocabParallelEmbedding",
      "input_shapes": [
        [
          26
        ]
      ],
      "input_dtypes": [
        "torch.int32"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.117528037,
      "end_timestamp": 3093821.117795245,
      "duration_time": 0.00026720762252807617,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 79976.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.00043015642268768277
    },
    {
      "iter": 0,
      "ops_idx": 2,
      "module_name": "model.decoder.embed_positions",
      "operator_name": "OPTLearnedPositionalEmbedding",
      "input_shapes": [
        [
          26
        ]
      ],
      "input_dtypes": [
        "torch.int64"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.117876217,
      "end_timestamp": 3093821.117953026,
      "duration_time": 7.680943235754967e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0014983907539351186
    },
    {
      "iter": 0,
      "ops_idx": 3,
      "module_name": "model.decoder.layers.0.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.118070156,
      "end_timestamp": 3093821.118124012,
      "duration_time": 5.3856056183576584e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0021724416151905537
    },
    {
      "iter": 0,
      "ops_idx": 4,
      "module_name": "model.decoder.layers.0.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.11821667,
      "end_timestamp": 3093821.118769454,
      "duration_time": 0.0005527837201952934,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.0022241189748785843,
      "memory_efficiency": 0.009616300575133855
    },
    {
      "iter": 0,
      "ops_idx": 5,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093821.119047419,
      "end_timestamp": 3093821.120047722,
      "duration_time": 0.0010003028437495232,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0001150556993601591
    },
    {
      "iter": 0,
      "ops_idx": 6,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093821.150173157,
      "end_timestamp": 3093821.15464225,
      "duration_time": 0.004469092935323715,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 1.5797795711969036e-06,
      "memory_efficiency": 2.809369188256157e-05
    },
    {
      "iter": 0,
      "ops_idx": 7,
      "module_name": "model.decoder.layers.0.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.118938612,
      "end_timestamp": 3093821.184667204,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 8,
      "module_name": "model.decoder.layers.0.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.184867472,
      "end_timestamp": 3093821.185040945,
      "duration_time": 0.0001734732650220394,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.002362432737467502,
      "memory_efficiency": 0.010434895184054736
    },
    {
      "iter": 0,
      "ops_idx": 9,
      "module_name": "model.decoder.layers.0.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.185180129,
      "end_timestamp": 3093821.185230699,
      "duration_time": 5.056988447904587e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0023136129118847813
    },
    {
      "iter": 0,
      "ops_idx": 10,
      "module_name": "model.decoder.layers.0.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.185308606,
      "end_timestamp": 3093821.185419728,
      "duration_time": 0.00011112214997410774,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.014752015523779291,
      "memory_efficiency": 0.06361030579803034
    },
    {
      "iter": 0,
      "ops_idx": 11,
      "module_name": "model.decoder.layers.0.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.185535413,
      "end_timestamp": 3093821.185569256,
      "duration_time": 3.3842865377664566e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.013567599020066197
    },
    {
      "iter": 0,
      "ops_idx": 12,
      "module_name": "model.decoder.layers.0.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.185675164,
      "end_timestamp": 3093821.195748116,
      "duration_time": 0.010072951670736074,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.00016274035010176703,
      "memory_efficiency": 0.00070173214087019
    },
    {
      "iter": 0,
      "ops_idx": 13,
      "module_name": "model.decoder.layers.1.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.196036816,
      "end_timestamp": 3093821.196081316,
      "duration_time": 4.449998959898949e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0026291947197645896
    },
    {
      "iter": 0,
      "ops_idx": 14,
      "module_name": "model.decoder.layers.1.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.196210202,
      "end_timestamp": 3093821.196306003,
      "duration_time": 9.58009622991085e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.012833448971543024,
      "memory_efficiency": 0.05548727568979856
    },
    {
      "iter": 0,
      "ops_idx": 15,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093821.196612315,
      "end_timestamp": 3093821.196638535,
      "duration_time": 2.6219990104436874e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.004389419782430888
    },
    {
      "iter": 0,
      "ops_idx": 16,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093821.226243223,
      "end_timestamp": 3093821.226294993,
      "duration_time": 5.176989361643791e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.0001363762068609519,
      "memory_efficiency": 0.0024252188124962958
    },
    {
      "iter": 0,
      "ops_idx": 17,
      "module_name": "model.decoder.layers.1.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.196527554,
      "end_timestamp": 3093821.256022389,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 18,
      "module_name": "model.decoder.layers.1.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.256307857,
      "end_timestamp": 3093821.256406662,
      "duration_time": 9.880494326353073e-05,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.0041477572561362695,
      "memory_efficiency": 0.018320696090201313
    },
    {
      "iter": 0,
      "ops_idx": 19,
      "module_name": "model.decoder.layers.1.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.256576633,
      "end_timestamp": 3093821.256619153,
      "duration_time": 4.251999780535698e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0027516261458626393
    },
    {
      "iter": 0,
      "ops_idx": 20,
      "module_name": "model.decoder.layers.1.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.256740819,
      "end_timestamp": 3093821.256816954,
      "duration_time": 7.613468915224075e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.021531258611640652,
      "memory_efficiency": 0.09284222500276074
    },
    {
      "iter": 0,
      "ops_idx": 21,
      "module_name": "model.decoder.layers.1.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.257036959,
      "end_timestamp": 3093821.257069631,
      "duration_time": 3.267219290137291e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.014053737639230806
    },
    {
      "iter": 0,
      "ops_idx": 22,
      "module_name": "model.decoder.layers.1.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.257340253,
      "end_timestamp": 3093821.257426617,
      "duration_time": 8.636433631181717e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.01898093300381754,
      "memory_efficiency": 0.08184528756484409
    },
    {
      "iter": 0,
      "ops_idx": 23,
      "module_name": "model.decoder.layers.2.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.257667594,
      "end_timestamp": 3093821.257707377,
      "duration_time": 3.978284075856209e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.00294094477549499
    },
    {
      "iter": 0,
      "ops_idx": 24,
      "module_name": "model.decoder.layers.2.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.257909051,
      "end_timestamp": 3093821.257989097,
      "duration_time": 8.004577830433846e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.015359420410853697,
      "memory_efficiency": 0.0664086791214387
    },
    {
      "iter": 0,
      "ops_idx": 25,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093821.258276002,
      "end_timestamp": 3093821.258299669,
      "duration_time": 2.366676926612854e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.004862959619261294
    },
    {
      "iter": 0,
      "ops_idx": 26,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093821.287824542,
      "end_timestamp": 3093821.287872288,
      "duration_time": 4.774611443281174e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.00014786924140057275,
      "memory_efficiency": 0.002629602877867592
    },
    {
      "iter": 0,
      "ops_idx": 27,
      "module_name": "model.decoder.layers.2.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.258200843,
      "end_timestamp": 3093821.31736355,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 28,
      "module_name": "model.decoder.layers.2.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.317633857,
      "end_timestamp": 3093821.317714237,
      "duration_time": 8.038012310862541e-05,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.005098510732679697,
      "memory_efficiency": 0.022520186182029923
    },
    {
      "iter": 0,
      "ops_idx": 29,
      "module_name": "model.decoder.layers.2.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.317880523,
      "end_timestamp": 3093821.317917239,
      "duration_time": 3.671599552035332e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0031865985390041912
    },
    {
      "iter": 0,
      "ops_idx": 30,
      "module_name": "model.decoder.layers.2.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.318043392,
      "end_timestamp": 3093821.31811728,
      "duration_time": 7.388787344098091e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.022185990814354198,
      "memory_efficiency": 0.09566541316734022
    },
    {
      "iter": 0,
      "ops_idx": 31,
      "module_name": "model.decoder.layers.2.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.318328225,
      "end_timestamp": 3093821.318355848,
      "duration_time": 2.7623027563095093e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.01662259598754806
    },
    {
      "iter": 0,
      "ops_idx": 32,
      "module_name": "model.decoder.layers.2.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.318621942,
      "end_timestamp": 3093821.318700055,
      "duration_time": 7.811328396201134e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.02098587587549121,
      "memory_efficiency": 0.09049054888314768
    },
    {
      "iter": 0,
      "ops_idx": 33,
      "module_name": "model.decoder.layers.3.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.31894242,
      "end_timestamp": 3093821.318978548,
      "duration_time": 3.612786531448364e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003238473589978133
    },
    {
      "iter": 0,
      "ops_idx": 34,
      "module_name": "model.decoder.layers.3.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.319102467,
      "end_timestamp": 3093821.319175906,
      "duration_time": 7.343897596001625e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.016741202406739743,
      "memory_efficiency": 0.07238301374644407
    },
    {
      "iter": 0,
      "ops_idx": 35,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093821.319446966,
      "end_timestamp": 3093821.319468082,
      "duration_time": 2.1115876734256744e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.005450426932680634
    },
    {
      "iter": 0,
      "ops_idx": 36,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093821.34899859,
      "end_timestamp": 3093821.34904472,
      "duration_time": 4.613026976585388e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.00015304878460153362,
      "memory_efficiency": 0.0027217122413719986
    },
    {
      "iter": 0,
      "ops_idx": 37,
      "module_name": "model.decoder.layers.3.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.319382189,
      "end_timestamp": 3093821.378584897,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 38,
      "module_name": "model.decoder.layers.3.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.378859947,
      "end_timestamp": 3093821.378941957,
      "duration_time": 8.20099376142025e-05,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.004997186100681407,
      "memory_efficiency": 0.022072634005116516
    },
    {
      "iter": 0,
      "ops_idx": 39,
      "module_name": "model.decoder.layers.3.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.379104171,
      "end_timestamp": 3093821.379140415,
      "duration_time": 3.624428063631058e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0032280717296408186
    },
    {
      "iter": 0,
      "ops_idx": 40,
      "module_name": "model.decoder.layers.3.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.379262995,
      "end_timestamp": 3093821.379337824,
      "duration_time": 7.482897490262985e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.021906964295406322,
      "memory_efficiency": 0.09446225810236458
    },
    {
      "iter": 0,
      "ops_idx": 41,
      "module_name": "model.decoder.layers.3.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.379549277,
      "end_timestamp": 3093821.37957744,
      "duration_time": 2.816319465637207e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.016303776355511754
    },
    {
      "iter": 0,
      "ops_idx": 42,
      "module_name": "model.decoder.layers.3.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.379844541,
      "end_timestamp": 3093821.379922155,
      "duration_time": 7.761362940073013e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.021120976999928143,
      "memory_efficiency": 0.09107310140454644
    },
    {
      "iter": 0,
      "ops_idx": 43,
      "module_name": "model.decoder.layers.4.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.380176266,
      "end_timestamp": 3093821.380211947,
      "duration_time": 3.568083047866821e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0032790474917109977
    },
    {
      "iter": 0,
      "ops_idx": 44,
      "module_name": "model.decoder.layers.4.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.38034227,
      "end_timestamp": 3093821.380417308,
      "duration_time": 7.503805682063103e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.016384442950450953,
      "memory_efficiency": 0.07084051255678464
    },
    {
      "iter": 0,
      "ops_idx": 45,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093821.380686669,
      "end_timestamp": 3093821.380707293,
      "duration_time": 2.0623672753572464e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.005580506665071146
    },
    {
      "iter": 0,
      "ops_idx": 46,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093821.41021183,
      "end_timestamp": 3093821.410254676,
      "duration_time": 4.28459607064724e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.00016478056751656136,
      "memory_efficiency": 0.0029303420404003396
    },
    {
      "iter": 0,
      "ops_idx": 47,
      "module_name": "model.decoder.layers.4.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.380624565,
      "end_timestamp": 3093821.43983888,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 48,
      "module_name": "model.decoder.layers.4.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.440126415,
      "end_timestamp": 3093821.440212478,
      "duration_time": 8.606305345892906e-05,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.004761844994949144,
      "memory_efficiency": 0.021033129374204467
    },
    {
      "iter": 0,
      "ops_idx": 49,
      "module_name": "model.decoder.layers.4.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.440377976,
      "end_timestamp": 3093821.440415333,
      "duration_time": 3.7357211112976074e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003131902360950133
    },
    {
      "iter": 0,
      "ops_idx": 50,
      "module_name": "model.decoder.layers.4.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.440545663,
      "end_timestamp": 3093821.440637449,
      "duration_time": 9.178603067994118e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.017859751307581204,
      "memory_efficiency": 0.07701078136209596
    },
    {
      "iter": 0,
      "ops_idx": 51,
      "module_name": "model.decoder.layers.4.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.440857797,
      "end_timestamp": 3093821.440888985,
      "duration_time": 3.1188130378723145e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.014722473632067471
    },
    {
      "iter": 0,
      "ops_idx": 52,
      "module_name": "model.decoder.layers.4.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.441155807,
      "end_timestamp": 3093821.441234472,
      "duration_time": 7.866509258747101e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.020838667158892474,
      "memory_efficiency": 0.08985578874044807
    },
    {
      "iter": 0,
      "ops_idx": 53,
      "module_name": "model.decoder.layers.5.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.441473675,
      "end_timestamp": 3093821.44151034,
      "duration_time": 3.6665238440036774e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0031910098682321557
    },
    {
      "iter": 0,
      "ops_idx": 54,
      "module_name": "model.decoder.layers.5.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.441632957,
      "end_timestamp": 3093821.441707066,
      "duration_time": 7.410859689116478e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.016589934402561894,
      "memory_efficiency": 0.07172898461760478
    },
    {
      "iter": 0,
      "ops_idx": 55,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093821.442034618,
      "end_timestamp": 3093821.442055841,
      "duration_time": 2.1222978830337524e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.005422921267538529
    },
    {
      "iter": 0,
      "ops_idx": 56,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093821.471498405,
      "end_timestamp": 3093821.471541723,
      "duration_time": 4.331767559051514e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.00016298616268668652,
      "memory_efficiency": 0.002898431603449386
    },
    {
      "iter": 0,
      "ops_idx": 57,
      "module_name": "model.decoder.layers.5.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.441969304,
      "end_timestamp": 3093821.501081193,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 58,
      "module_name": "model.decoder.layers.5.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.501358511,
      "end_timestamp": 3093821.501439756,
      "duration_time": 8.124485611915588e-05,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.005044244521307178,
      "memory_efficiency": 0.022280491642275524
    },
    {
      "iter": 0,
      "ops_idx": 59,
      "module_name": "model.decoder.layers.5.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.501600942,
      "end_timestamp": 3093821.501637492,
      "duration_time": 3.6549754440784454e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003201092304814161
    },
    {
      "iter": 0,
      "ops_idx": 60,
      "module_name": "model.decoder.layers.5.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.501756294,
      "end_timestamp": 3093821.501828219,
      "duration_time": 7.192464545369148e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.022791571249512962,
      "memory_efficiency": 0.09827666019346079
    },
    {
      "iter": 0,
      "ops_idx": 61,
      "module_name": "model.decoder.layers.5.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.502038967,
      "end_timestamp": 3093821.502064989,
      "duration_time": 2.6022084057331085e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.01764525954656868
    },
    {
      "iter": 0,
      "ops_idx": 62,
      "module_name": "model.decoder.layers.5.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.502329162,
      "end_timestamp": 3093821.502405346,
      "duration_time": 7.618404924869537e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.021517308381738976,
      "memory_efficiency": 0.09278207197563247
    },
    {
      "iter": 0,
      "ops_idx": 63,
      "module_name": "model.decoder.layers.6.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.502643993,
      "end_timestamp": 3093821.502678633,
      "duration_time": 3.4640077501535416e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0033775657019836734
    },
    {
      "iter": 0,
      "ops_idx": 64,
      "module_name": "model.decoder.layers.6.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.502803041,
      "end_timestamp": 3093821.502880454,
      "duration_time": 7.74129293859005e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.01588180128104352,
      "memory_efficiency": 0.0686672684861194
    },
    {
      "iter": 0,
      "ops_idx": 65,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093821.503144586,
      "end_timestamp": 3093821.503166222,
      "duration_time": 2.163602039217949e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.005319395211013839
    },
    {
      "iter": 0,
      "ops_idx": 66,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093821.532998858,
      "end_timestamp": 3093821.533043178,
      "duration_time": 4.431977868080139e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.00015930092457937218,
      "memory_efficiency": 0.0028328959136681062
    },
    {
      "iter": 0,
      "ops_idx": 67,
      "module_name": "model.decoder.layers.6.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.503080307,
      "end_timestamp": 3093821.562969675,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 68,
      "module_name": "model.decoder.layers.6.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.563251681,
      "end_timestamp": 3093821.563364949,
      "duration_time": 0.0001132679171860218,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.0036181376911026755,
      "memory_efficiency": 0.015981359794652608
    },
    {
      "iter": 0,
      "ops_idx": 69,
      "module_name": "model.decoder.layers.6.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.563537994,
      "end_timestamp": 3093821.563584486,
      "duration_time": 4.6492088586091995e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.002516538646496564
    },
    {
      "iter": 0,
      "ops_idx": 70,
      "module_name": "model.decoder.layers.6.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.563707528,
      "end_timestamp": 3093821.563785132,
      "duration_time": 7.760385051369667e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.021123638461269967,
      "memory_efficiency": 0.09108457755636787
    },
    {
      "iter": 0,
      "ops_idx": 71,
      "module_name": "model.decoder.layers.6.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.56400793,
      "end_timestamp": 3093821.564037768,
      "duration_time": 2.983817830681801e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.01538855430156454
    },
    {
      "iter": 0,
      "ops_idx": 72,
      "module_name": "model.decoder.layers.6.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.564306472,
      "end_timestamp": 3093821.564389394,
      "duration_time": 8.292216807603836e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.019768847335860505,
      "memory_efficiency": 0.0852427535940192
    },
    {
      "iter": 0,
      "ops_idx": 73,
      "module_name": "model.decoder.layers.7.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.564632194,
      "end_timestamp": 3093821.564669022,
      "duration_time": 3.6827754229307175e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0031769283827286846
    },
    {
      "iter": 0,
      "ops_idx": 74,
      "module_name": "model.decoder.layers.7.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.564799924,
      "end_timestamp": 3093821.564876471,
      "duration_time": 7.654726505279541e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.016061406769299433,
      "memory_efficiency": 0.06944381883235563
    },
    {
      "iter": 0,
      "ops_idx": 75,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093821.565151009,
      "end_timestamp": 3093821.565174163,
      "duration_time": 2.315407618880272e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.004970638531249845
    },
    {
      "iter": 0,
      "ops_idx": 76,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093821.595107407,
      "end_timestamp": 3093821.595155034,
      "duration_time": 4.7627370804548264e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.00014823790609769678,
      "memory_efficiency": 0.0026361589522705116
    },
    {
      "iter": 0,
      "ops_idx": 77,
      "module_name": "model.decoder.layers.7.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.565083046,
      "end_timestamp": 3093821.625027407,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 78,
      "module_name": "model.decoder.layers.7.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.625312425,
      "end_timestamp": 3093821.625416988,
      "duration_time": 0.00010456284508109093,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.003919355102145679,
      "memory_efficiency": 0.01731184089661004
    },
    {
      "iter": 0,
      "ops_idx": 79,
      "module_name": "model.decoder.layers.7.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.625584932,
      "end_timestamp": 3093821.625625974,
      "duration_time": 4.1041988879442215e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.002850718029940473
    },
    {
      "iter": 0,
      "ops_idx": 80,
      "module_name": "model.decoder.layers.7.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.625744988,
      "end_timestamp": 3093821.625820083,
      "duration_time": 7.509486749768257e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.021829397082355276,
      "memory_efficiency": 0.09412779030478637
    },
    {
      "iter": 0,
      "ops_idx": 81,
      "module_name": "model.decoder.layers.7.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.626038944,
      "end_timestamp": 3093821.626069049,
      "duration_time": 3.0105002224445343e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.015252163866687563
    },
    {
      "iter": 0,
      "ops_idx": 82,
      "module_name": "model.decoder.layers.7.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.626335484,
      "end_timestamp": 3093821.62641811,
      "duration_time": 8.262600749731064e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.019839705815473705,
      "memory_efficiency": 0.0855482935081627
    },
    {
      "iter": 0,
      "ops_idx": 83,
      "module_name": "model.decoder.layers.8.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.626661124,
      "end_timestamp": 3093821.626697691,
      "duration_time": 3.656698390841484e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0031995840284852785
    },
    {
      "iter": 0,
      "ops_idx": 84,
      "module_name": "model.decoder.layers.8.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.626825812,
      "end_timestamp": 3093821.626903364,
      "duration_time": 7.755216211080551e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.015853288001612315,
      "memory_efficiency": 0.06854398719204734
    },
    {
      "iter": 0,
      "ops_idx": 85,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093821.627182649,
      "end_timestamp": 3093821.627205248,
      "duration_time": 2.2599007934331894e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.005092725468037667
    },
    {
      "iter": 0,
      "ops_idx": 86,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093821.657699199,
      "end_timestamp": 3093821.657746875,
      "duration_time": 4.7676265239715576e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.00014808588058452812,
      "memory_efficiency": 0.0026334554371706094
    },
    {
      "iter": 0,
      "ops_idx": 87,
      "module_name": "model.decoder.layers.8.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.627110322,
      "end_timestamp": 3093821.687673991,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 88,
      "module_name": "model.decoder.layers.8.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.68796023,
      "end_timestamp": 3093821.688079584,
      "duration_time": 0.00011935411021113396,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.0034336389391072014,
      "memory_efficiency": 0.015166426481154127
    },
    {
      "iter": 0,
      "ops_idx": 89,
      "module_name": "model.decoder.layers.8.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.688249866,
      "end_timestamp": 3093821.688290976,
      "duration_time": 4.1109975427389145e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.002846003590780371
    },
    {
      "iter": 0,
      "ops_idx": 90,
      "module_name": "model.decoder.layers.8.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.68841733,
      "end_timestamp": 3093821.688490751,
      "duration_time": 7.342128083109856e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.022326982897844395,
      "memory_efficiency": 0.09627336735037752
    },
    {
      "iter": 0,
      "ops_idx": 91,
      "module_name": "model.decoder.layers.8.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.688704439,
      "end_timestamp": 3093821.688734851,
      "duration_time": 3.0411873012781143e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.015098262015669371
    },
    {
      "iter": 0,
      "ops_idx": 92,
      "module_name": "model.decoder.layers.8.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.689005854,
      "end_timestamp": 3093821.689087021,
      "duration_time": 8.116709068417549e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.020196309460348377,
      "memory_efficiency": 0.08708595911477797
    },
    {
      "iter": 0,
      "ops_idx": 93,
      "module_name": "model.decoder.layers.9.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.689331126,
      "end_timestamp": 3093821.689366142,
      "duration_time": 3.501586616039276e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003341317822821207
    },
    {
      "iter": 0,
      "ops_idx": 94,
      "module_name": "model.decoder.layers.9.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.689491904,
      "end_timestamp": 3093821.689565563,
      "duration_time": 7.365923374891281e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.016691142420531525,
      "memory_efficiency": 0.07216657214435238
    },
    {
      "iter": 0,
      "ops_idx": 95,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093821.68984857,
      "end_timestamp": 3093821.68987195,
      "duration_time": 2.3379921913146973e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.004922623081766571
    },
    {
      "iter": 0,
      "ops_idx": 96,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093821.719535177,
      "end_timestamp": 3093821.719587875,
      "duration_time": 5.2697956562042236e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.00013397448746789133,
      "memory_efficiency": 0.0023825083193064795
    },
    {
      "iter": 0,
      "ops_idx": 97,
      "module_name": "model.decoder.layers.9.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.689778093,
      "end_timestamp": 3093821.74935844,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 98,
      "module_name": "model.decoder.layers.9.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.749644122,
      "end_timestamp": 3093821.749761586,
      "duration_time": 0.00011746399104595184,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.0034888898011571994,
      "memory_efficiency": 0.01541047023536422
    },
    {
      "iter": 0,
      "ops_idx": 99,
      "module_name": "model.decoder.layers.9.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.749932752,
      "end_timestamp": 3093821.749977421,
      "duration_time": 4.4669024646282196e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0026192454079693043
    },
    {
      "iter": 0,
      "ops_idx": 100,
      "module_name": "model.decoder.layers.9.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.750101018,
      "end_timestamp": 3093821.750175865,
      "duration_time": 7.484667003154755e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.021901785086267972,
      "memory_efficiency": 0.09443992548777701
    },
    {
      "iter": 0,
      "ops_idx": 101,
      "module_name": "model.decoder.layers.9.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.750389908,
      "end_timestamp": 3093821.750422132,
      "duration_time": 3.2224226742982864e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.01424910613981519
    },
    {
      "iter": 0,
      "ops_idx": 102,
      "module_name": "model.decoder.layers.9.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.750693612,
      "end_timestamp": 3093821.750778107,
      "duration_time": 8.44951719045639e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.019400820715594336,
      "memory_efficiency": 0.08365583241574286
    },
    {
      "iter": 0,
      "ops_idx": 103,
      "module_name": "model.decoder.layers.10.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.751020071,
      "end_timestamp": 3093821.751057303,
      "duration_time": 3.723194822669029e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003142439309672484
    },
    {
      "iter": 0,
      "ops_idx": 104,
      "module_name": "model.decoder.layers.10.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.751183134,
      "end_timestamp": 3093821.751259377,
      "duration_time": 7.624318823218346e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.01612546365907811,
      "memory_efficiency": 0.0697207780746343
    },
    {
      "iter": 0,
      "ops_idx": 105,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093821.751546816,
      "end_timestamp": 3093821.751570137,
      "duration_time": 2.3321248590946198e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.004935007781025838
    },
    {
      "iter": 0,
      "ops_idx": 106,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093821.78211999,
      "end_timestamp": 3093821.782174966,
      "duration_time": 5.49759715795517e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.00012842304588994008,
      "memory_efficiency": 0.0022837853759044187
    },
    {
      "iter": 0,
      "ops_idx": 107,
      "module_name": "model.decoder.layers.10.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.751470694,
      "end_timestamp": 3093821.812505258,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 108,
      "module_name": "model.decoder.layers.10.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.81278686,
      "end_timestamp": 3093821.812891087,
      "duration_time": 0.00010422710329294205,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.003931980333480051,
      "memory_efficiency": 0.017367606702577428
    },
    {
      "iter": 0,
      "ops_idx": 109,
      "module_name": "model.decoder.layers.10.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.813055928,
      "end_timestamp": 3093821.813095908,
      "duration_time": 3.998028114438057e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0029264210839519606
    },
    {
      "iter": 0,
      "ops_idx": 110,
      "module_name": "model.decoder.layers.10.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.813219866,
      "end_timestamp": 3093821.813297675,
      "duration_time": 7.780920714139938e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.021067888257424106,
      "memory_efficiency": 0.09084418413289151
    },
    {
      "iter": 0,
      "ops_idx": 111,
      "module_name": "model.decoder.layers.10.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.813512384,
      "end_timestamp": 3093821.813543204,
      "duration_time": 3.082025796175003e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.014898201945749116
    },
    {
      "iter": 0,
      "ops_idx": 112,
      "module_name": "model.decoder.layers.10.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.813810469,
      "end_timestamp": 3093821.813894547,
      "duration_time": 8.407793939113617e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.019497096305223994,
      "memory_efficiency": 0.08407097024469624
    },
    {
      "iter": 0,
      "ops_idx": 113,
      "module_name": "model.decoder.layers.11.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.814130613,
      "end_timestamp": 3093821.814164919,
      "duration_time": 3.430573269724846e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003410483568905858
    },
    {
      "iter": 0,
      "ops_idx": 114,
      "module_name": "model.decoder.layers.11.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.814287207,
      "end_timestamp": 3093821.814364994,
      "duration_time": 7.778685539960861e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.01580545652314044,
      "memory_efficiency": 0.06833718086597673
    },
    {
      "iter": 0,
      "ops_idx": 115,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093821.814649101,
      "end_timestamp": 3093821.814672229,
      "duration_time": 2.3127999156713486e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.004976242971980108
    },
    {
      "iter": 0,
      "ops_idx": 116,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093821.844592372,
      "end_timestamp": 3093821.844640544,
      "duration_time": 4.817219451069832e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.00014656134711564468,
      "memory_efficiency": 0.0026063442032235756
    },
    {
      "iter": 0,
      "ops_idx": 117,
      "module_name": "model.decoder.layers.11.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.8145761,
      "end_timestamp": 3093821.874651054,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 118,
      "module_name": "model.decoder.layers.11.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.874935202,
      "end_timestamp": 3093821.875044864,
      "duration_time": 0.00010966230183839798,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.0037370993814024147,
      "memory_efficiency": 0.016506815080429962
    },
    {
      "iter": 0,
      "ops_idx": 119,
      "module_name": "model.decoder.layers.11.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.875212303,
      "end_timestamp": 3093821.875253586,
      "duration_time": 4.1283201426267624e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0028340616435041845
    },
    {
      "iter": 0,
      "ops_idx": 120,
      "module_name": "model.decoder.layers.11.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.875381336,
      "end_timestamp": 3093821.87545789,
      "duration_time": 7.655378431081772e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.02141338532394569,
      "memory_efficiency": 0.09233395846361497
    },
    {
      "iter": 0,
      "ops_idx": 121,
      "module_name": "model.decoder.layers.11.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.875672305,
      "end_timestamp": 3093821.875704107,
      "duration_time": 3.1801871955394745e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.014438345886627683
    },
    {
      "iter": 0,
      "ops_idx": 122,
      "module_name": "model.decoder.layers.11.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.875975004,
      "end_timestamp": 3093821.876067558,
      "duration_time": 9.255390614271164e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.017711577498697027,
      "memory_efficiency": 0.07637185976665782
    },
    {
      "iter": 0,
      "ops_idx": 123,
      "module_name": "model.decoder.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.876319367,
      "end_timestamp": 3093821.876356427,
      "duration_time": 3.7060119211673737e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003157009210223701
    },
    {
      "iter": 0,
      "ops_idx": 124,
      "module_name": "logits_processor",
      "operator_name": "LogitsProcessor",
      "input_shapes": [
        [],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "VocabParallelEmbedding",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          50272
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.87658721,
      "end_timestamp": 3093821.876824441,
      "duration_time": 0.00023723067715764046,
      "ops_type": "TensorCore",
      "computes_ops": 617742336.0,
      "memory_byte": 77626112.0,
      "computes_efficiency": 0.017396935088906332,
      "memory_efficiency": 0.47027572497409204
    },
    {
      "iter": 1,
      "ops_idx": 0,
      "module_name": "model.decoder.embed_tokens",
      "operator_name": "VocabParallelEmbedding",
      "input_shapes": [
        [
          4
        ]
      ],
      "input_dtypes": [
        "torch.int32"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.878692346,
      "end_timestamp": 3093821.878836351,
      "duration_time": 0.00014400482177734375,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12304.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.00012279618204972503
    },
    {
      "iter": 1,
      "ops_idx": 1,
      "module_name": "lm_head",
      "operator_name": "VocabParallelEmbedding",
      "input_shapes": [
        [
          4
        ]
      ],
      "input_dtypes": [
        "torch.int32"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.878692346,
      "end_timestamp": 3093821.878917495,
      "duration_time": 0.00022514862939715385,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12304.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 7.854030627837545e-05
    },
    {
      "iter": 1,
      "ops_idx": 2,
      "module_name": "model.decoder.embed_positions",
      "operator_name": "OPTLearnedPositionalEmbedding",
      "input_shapes": [
        [
          4
        ]
      ],
      "input_dtypes": [
        "torch.int64"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.878997673,
      "end_timestamp": 3093821.879054698,
      "duration_time": 5.702534690499306e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0003104976713959622
    },
    {
      "iter": 1,
      "ops_idx": 3,
      "module_name": "model.decoder.layers.0.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.879151201,
      "end_timestamp": 3093821.879193211,
      "duration_time": 4.2010098695755005e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0004729286222591506
    },
    {
      "iter": 1,
      "ops_idx": 4,
      "module_name": "model.decoder.layers.0.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.879278449,
      "end_timestamp": 3093821.879406432,
      "duration_time": 0.00012798327952623367,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.001477905510110994,
      "memory_efficiency": 0.04001672488957177
    },
    {
      "iter": 1,
      "ops_idx": 5,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093821.879613915,
      "end_timestamp": 3093821.879638429,
      "duration_time": 2.4513807147741318e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0007222965130562643
    },
    {
      "iter": 1,
      "ops_idx": 6,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093821.910735301,
      "end_timestamp": 3093821.929732825,
      "duration_time": 0.018997523933649063,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 6.482039705080505e-08,
      "memory_efficiency": 4.604463834628225e-06
    },
    {
      "iter": 1,
      "ops_idx": 7,
      "module_name": "model.decoder.layers.0.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.879537102,
      "end_timestamp": 3093821.961009552,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 8,
      "module_name": "model.decoder.layers.0.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.961247673,
      "end_timestamp": 3093821.961949679,
      "duration_time": 0.0007020062766969204,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 8.981267940787824e-05,
      "memory_efficiency": 0.002440211768781977
    },
    {
      "iter": 1,
      "ops_idx": 9,
      "module_name": "model.decoder.layers.0.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.962118537,
      "end_timestamp": 3093821.962177906,
      "duration_time": 5.936902016401291e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.00033464891356245415
    },
    {
      "iter": 1,
      "ops_idx": 10,
      "module_name": "model.decoder.layers.0.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.962265621,
      "end_timestamp": 3093821.962378454,
      "duration_time": 0.00011283298954367638,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0022351287482954866,
      "memory_efficiency": 0.0604937046286469
    },
    {
      "iter": 1,
      "ops_idx": 11,
      "module_name": "model.decoder.layers.0.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.962488391,
      "end_timestamp": 3093821.962523404,
      "duration_time": 3.5013072192668915e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0020175604243226923
    },
    {
      "iter": 1,
      "ops_idx": 12,
      "module_name": "model.decoder.layers.0.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.962629661,
      "end_timestamp": 3093821.962775156,
      "duration_time": 0.00014549493789672852,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0017333679255851677,
      "memory_efficiency": 0.04691356029628464
    },
    {
      "iter": 1,
      "ops_idx": 13,
      "module_name": "model.decoder.layers.1.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.962917645,
      "end_timestamp": 3093821.96295598,
      "duration_time": 3.833509981632233e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005182659805856315
    },
    {
      "iter": 1,
      "ops_idx": 14,
      "module_name": "model.decoder.layers.1.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093821.963042256,
      "end_timestamp": 3093821.963112337,
      "duration_time": 7.008109241724014e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0026989761073896385,
      "memory_efficiency": 0.07307922166473763
    },
    {
      "iter": 1,
      "ops_idx": 15,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093821.963336539,
      "end_timestamp": 3093821.963368554,
      "duration_time": 3.201514482498169e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005530581704797085
    },
    {
      "iter": 1,
      "ops_idx": 16,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093821.992997873,
      "end_timestamp": 3093821.993068896,
      "duration_time": 7.102265954017639e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 1.7338509319898186e-05,
      "memory_efficiency": 0.0012316268141224552
    },
    {
      "iter": 1,
      "ops_idx": 17,
      "module_name": "model.decoder.layers.1.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093821.963236557,
      "end_timestamp": 3093822.022682177,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 18,
      "module_name": "model.decoder.layers.1.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.022909503,
      "end_timestamp": 3093822.023036036,
      "duration_time": 0.00012653321027755737,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0004982807638642635,
      "memory_efficiency": 0.01353829539610185
    },
    {
      "iter": 1,
      "ops_idx": 19,
      "module_name": "model.decoder.layers.1.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.023164148,
      "end_timestamp": 3093822.023215257,
      "duration_time": 5.110912024974823e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0003887325393211444
    },
    {
      "iter": 1,
      "ops_idx": 20,
      "module_name": "model.decoder.layers.1.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.023292092,
      "end_timestamp": 3093822.023359632,
      "duration_time": 6.753997877240181e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0037340292856036187,
      "memory_efficiency": 0.10106141082489464
    },
    {
      "iter": 1,
      "ops_idx": 21,
      "module_name": "model.decoder.layers.1.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.023461806,
      "end_timestamp": 3093822.023491994,
      "duration_time": 3.018788993358612e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.002340043936336509
    },
    {
      "iter": 1,
      "ops_idx": 22,
      "module_name": "model.decoder.layers.1.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.023593444,
      "end_timestamp": 3093822.023662709,
      "duration_time": 6.926525384187698e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0036410212147770997,
      "memory_efficiency": 0.09854414967430078
    },
    {
      "iter": 1,
      "ops_idx": 23,
      "module_name": "model.decoder.layers.2.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.023794579,
      "end_timestamp": 3093822.023833102,
      "duration_time": 3.852322697639465e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.000515735042376602
    },
    {
      "iter": 1,
      "ops_idx": 24,
      "module_name": "model.decoder.layers.2.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.023918832,
      "end_timestamp": 3093822.023981342,
      "duration_time": 6.250990554690361e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.003025875536989443,
      "memory_efficiency": 0.08193056192387968
    },
    {
      "iter": 1,
      "ops_idx": 25,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093822.024936521,
      "end_timestamp": 3093822.024961862,
      "duration_time": 2.5340821593999863e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0006987238893919573
    },
    {
      "iter": 1,
      "ops_idx": 26,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093822.054425155,
      "end_timestamp": 3093822.054478608,
      "duration_time": 5.345325917005539e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 2.303745484337374e-05,
      "memory_efficiency": 0.0016364467435312907
    },
    {
      "iter": 1,
      "ops_idx": 27,
      "module_name": "model.decoder.layers.2.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.024848935,
      "end_timestamp": 3093822.083899981,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 28,
      "module_name": "model.decoder.layers.2.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.084093542,
      "end_timestamp": 3093822.084179858,
      "duration_time": 8.631637319922447e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0007304415412099967,
      "memory_efficiency": 0.019846106997577526
    },
    {
      "iter": 1,
      "ops_idx": 29,
      "module_name": "model.decoder.layers.2.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.084296696,
      "end_timestamp": 3093822.08433491,
      "duration_time": 3.8214027881622314e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005199079814014858
    },
    {
      "iter": 1,
      "ops_idx": 30,
      "module_name": "model.decoder.layers.2.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.084417237,
      "end_timestamp": 3093822.08447926,
      "duration_time": 6.202282384037971e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004066184721518657,
      "memory_efficiency": 0.11005118953288494
    },
    {
      "iter": 1,
      "ops_idx": 31,
      "module_name": "model.decoder.layers.2.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.084581364,
      "end_timestamp": 3093822.084609612,
      "duration_time": 2.824794501066208e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0025007478867301314
    },
    {
      "iter": 1,
      "ops_idx": 32,
      "module_name": "model.decoder.layers.2.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.084707309,
      "end_timestamp": 3093822.084773344,
      "duration_time": 6.60349614918232e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0038191323654580066,
      "memory_efficiency": 0.10336472358914839
    },
    {
      "iter": 1,
      "ops_idx": 33,
      "module_name": "model.decoder.layers.3.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.084894494,
      "end_timestamp": 3093822.084931982,
      "duration_time": 3.748806193470955e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.000529976132982194
    },
    {
      "iter": 1,
      "ops_idx": 34,
      "module_name": "model.decoder.layers.3.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.08501319,
      "end_timestamp": 3093822.085075103,
      "duration_time": 6.19133934378624e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.00305502870237162,
      "memory_efficiency": 0.08271993187397286
    },
    {
      "iter": 1,
      "ops_idx": 35,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093822.085263149,
      "end_timestamp": 3093822.085284828,
      "duration_time": 2.167932689189911e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0008167337257672678
    },
    {
      "iter": 1,
      "ops_idx": 36,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093822.114666236,
      "end_timestamp": 3093822.114712636,
      "duration_time": 4.639988765120506e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 2.6539440216280835e-05,
      "memory_efficiency": 0.001885207407343786
    },
    {
      "iter": 1,
      "ops_idx": 37,
      "module_name": "model.decoder.layers.3.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.08519318,
      "end_timestamp": 3093822.144116642,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 38,
      "module_name": "model.decoder.layers.3.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.144302634,
      "end_timestamp": 3093822.144376859,
      "duration_time": 7.422501221299171e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008494315162977259,
      "memory_efficiency": 0.023079066302326666
    },
    {
      "iter": 1,
      "ops_idx": 39,
      "module_name": "model.decoder.layers.3.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.144493329,
      "end_timestamp": 3093822.144528227,
      "duration_time": 3.48980538547039e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005693090560256666
    },
    {
      "iter": 1,
      "ops_idx": 40,
      "module_name": "model.decoder.layers.3.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.144604376,
      "end_timestamp": 3093822.144662587,
      "duration_time": 5.821092054247856e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004332456115363415,
      "memory_efficiency": 0.11725781826180569
    },
    {
      "iter": 1,
      "ops_idx": 41,
      "module_name": "model.decoder.layers.3.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.144757222,
      "end_timestamp": 3093822.144781806,
      "duration_time": 2.4584122002124786e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0028734395632992998
    },
    {
      "iter": 1,
      "ops_idx": 42,
      "module_name": "model.decoder.layers.3.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.144888146,
      "end_timestamp": 3093822.144954593,
      "duration_time": 6.644707173109055e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0037954457903852613,
      "memory_efficiency": 0.1027236470170683
    },
    {
      "iter": 1,
      "ops_idx": 43,
      "module_name": "model.decoder.layers.4.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.145080637,
      "end_timestamp": 3093822.145115545,
      "duration_time": 3.4907832741737366e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005691495729380974
    },
    {
      "iter": 1,
      "ops_idx": 44,
      "module_name": "model.decoder.layers.4.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.145194171,
      "end_timestamp": 3093822.145252781,
      "duration_time": 5.8609992265701294e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.003227217522166194,
      "memory_efficiency": 0.08738222765921697
    },
    {
      "iter": 1,
      "ops_idx": 45,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093822.145429599,
      "end_timestamp": 3093822.145450271,
      "duration_time": 2.067210152745247e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0008565281764427032
    },
    {
      "iter": 1,
      "ops_idx": 46,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093822.174820643,
      "end_timestamp": 3093822.174867823,
      "duration_time": 4.7179870307445526e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 2.6100687355365002e-05,
      "memory_efficiency": 0.001854040957085186
    },
    {
      "iter": 1,
      "ops_idx": 47,
      "module_name": "model.decoder.layers.4.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.145361956,
      "end_timestamp": 3093822.204232277,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 48,
      "module_name": "model.decoder.layers.4.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.204417744,
      "end_timestamp": 3093822.204489885,
      "duration_time": 7.214071229100227e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008739734148585964,
      "memory_efficiency": 0.023745870033061774
    },
    {
      "iter": 1,
      "ops_idx": 49,
      "module_name": "model.decoder.layers.4.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.204606369,
      "end_timestamp": 3093822.204641905,
      "duration_time": 3.5536009818315506e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005590886033275003
    },
    {
      "iter": 1,
      "ops_idx": 50,
      "module_name": "model.decoder.layers.4.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.204713951,
      "end_timestamp": 3093822.20477213,
      "duration_time": 5.8179255574941635e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004334814122197508,
      "memory_efficiency": 0.11732163765880585
    },
    {
      "iter": 1,
      "ops_idx": 51,
      "module_name": "model.decoder.layers.4.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.204868861,
      "end_timestamp": 3093822.204893216,
      "duration_time": 2.435501664876938e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0029004697392991325
    },
    {
      "iter": 1,
      "ops_idx": 52,
      "module_name": "model.decoder.layers.4.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.204991728,
      "end_timestamp": 3093822.205055641,
      "duration_time": 6.391294300556183e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0039459340600736924,
      "memory_efficiency": 0.10679660833688066
    },
    {
      "iter": 1,
      "ops_idx": 53,
      "module_name": "model.decoder.layers.5.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.205184544,
      "end_timestamp": 3093822.205221883,
      "duration_time": 3.733905032277107e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005320911465452582
    },
    {
      "iter": 1,
      "ops_idx": 54,
      "module_name": "model.decoder.layers.5.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.205300842,
      "end_timestamp": 3093822.205359973,
      "duration_time": 5.9131067246198654e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.003198778625563468,
      "memory_efficiency": 0.0866121977122897
    },
    {
      "iter": 1,
      "ops_idx": 55,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093822.205534838,
      "end_timestamp": 3093822.205553226,
      "duration_time": 1.8388032913208008e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0009629217822331068
    },
    {
      "iter": 1,
      "ops_idx": 56,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093822.2350741,
      "end_timestamp": 3093822.235116544,
      "duration_time": 4.244409501552582e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 2.901291790791758e-05,
      "memory_efficiency": 0.0020609088700789583
    },
    {
      "iter": 1,
      "ops_idx": 57,
      "module_name": "model.decoder.layers.5.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.205473793,
      "end_timestamp": 3093822.264641569,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 58,
      "module_name": "model.decoder.layers.5.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.264832824,
      "end_timestamp": 3093822.264910213,
      "duration_time": 7.73891806602478e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.000814701281670048,
      "memory_efficiency": 0.02213544533667062
    },
    {
      "iter": 1,
      "ops_idx": 59,
      "module_name": "model.decoder.layers.5.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.265023966,
      "end_timestamp": 3093822.265064618,
      "duration_time": 4.065223038196564e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0004887254133531675
    },
    {
      "iter": 1,
      "ops_idx": 60,
      "module_name": "model.decoder.layers.5.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.265149248,
      "end_timestamp": 3093822.265211772,
      "duration_time": 6.252434104681015e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004033569238200897,
      "memory_efficiency": 0.10916845227864411
    },
    {
      "iter": 1,
      "ops_idx": 61,
      "module_name": "model.decoder.layers.5.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.265312352,
      "end_timestamp": 3093822.265337402,
      "duration_time": 2.5049783289432526e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0028200239488571817
    },
    {
      "iter": 1,
      "ops_idx": 62,
      "module_name": "model.decoder.layers.5.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.265432941,
      "end_timestamp": 3093822.265497865,
      "duration_time": 6.492435932159424e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0038844628013343075,
      "memory_efficiency": 0.10513289023018665
    },
    {
      "iter": 1,
      "ops_idx": 63,
      "module_name": "model.decoder.layers.6.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.265624622,
      "end_timestamp": 3093822.265659551,
      "duration_time": 3.492925316095352e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005688005410709443
    },
    {
      "iter": 1,
      "ops_idx": 64,
      "module_name": "model.decoder.layers.6.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.265742521,
      "end_timestamp": 3093822.265805401,
      "duration_time": 6.288010627031326e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.003008060978789978,
      "memory_efficiency": 0.08144820343098541
    },
    {
      "iter": 1,
      "ops_idx": 65,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093822.265990422,
      "end_timestamp": 3093822.26600905,
      "duration_time": 1.8627848476171494e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0009505250940384702
    },
    {
      "iter": 1,
      "ops_idx": 66,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093822.295799926,
      "end_timestamp": 3093822.295847881,
      "duration_time": 4.795519635081291e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 2.5678698828650082e-05,
      "memory_efficiency": 0.001824065347581221
    },
    {
      "iter": 1,
      "ops_idx": 67,
      "module_name": "model.decoder.layers.6.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.265925046,
      "end_timestamp": 3093822.325306687,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 68,
      "module_name": "model.decoder.layers.6.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.325527891,
      "end_timestamp": 3093822.325610634,
      "duration_time": 8.274288848042488e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0007619877167596678,
      "memory_efficiency": 0.02070321703308569
    },
    {
      "iter": 1,
      "ops_idx": 69,
      "module_name": "model.decoder.layers.6.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.325728861,
      "end_timestamp": 3093822.3257836,
      "duration_time": 5.473894998431206e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.00036295504577359215
    },
    {
      "iter": 1,
      "ops_idx": 70,
      "module_name": "model.decoder.layers.6.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.325858423,
      "end_timestamp": 3093822.325918034,
      "duration_time": 5.961116403341293e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004230688374812399,
      "memory_efficiency": 0.11450347686544865
    },
    {
      "iter": 1,
      "ops_idx": 71,
      "module_name": "model.decoder.layers.6.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.326024129,
      "end_timestamp": 3093822.326054206,
      "duration_time": 3.007706254720688e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0023486664855987493
    },
    {
      "iter": 1,
      "ops_idx": 72,
      "module_name": "model.decoder.layers.6.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.326156099,
      "end_timestamp": 3093822.326220488,
      "duration_time": 6.438931450247765e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.003916740854190811,
      "memory_efficiency": 0.10600649493728834
    },
    {
      "iter": 1,
      "ops_idx": 73,
      "module_name": "model.decoder.layers.7.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.326340508,
      "end_timestamp": 3093822.326375589,
      "duration_time": 3.508059307932854e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005663466992199048
    },
    {
      "iter": 1,
      "ops_idx": 74,
      "module_name": "model.decoder.layers.7.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.326458167,
      "end_timestamp": 3093822.326521758,
      "duration_time": 6.359117105603218e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.002974425393852753,
      "memory_efficiency": 0.08053746459164537
    },
    {
      "iter": 1,
      "ops_idx": 75,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093822.326698753,
      "end_timestamp": 3093822.326717077,
      "duration_time": 1.832377165555954e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0009662987379115863
    },
    {
      "iter": 1,
      "ops_idx": 76,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093822.356054584,
      "end_timestamp": 3093822.356095608,
      "duration_time": 4.102382808923721e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 3.0017360683226308e-05,
      "memory_efficiency": 0.0021322586402637614
    },
    {
      "iter": 1,
      "ops_idx": 77,
      "module_name": "model.decoder.layers.7.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.326631677,
      "end_timestamp": 3093822.385466274,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 78,
      "module_name": "model.decoder.layers.7.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.385654182,
      "end_timestamp": 3093822.385725251,
      "duration_time": 7.106876000761986e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.00088715582858824,
      "memory_efficiency": 0.024104036400395518
    },
    {
      "iter": 1,
      "ops_idx": 79,
      "module_name": "model.decoder.layers.7.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.385836774,
      "end_timestamp": 3093822.38587248,
      "duration_time": 3.570597618818283e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.00055642724882928
    },
    {
      "iter": 1,
      "ops_idx": 80,
      "module_name": "model.decoder.layers.7.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.385945899,
      "end_timestamp": 3093822.386004254,
      "duration_time": 5.835527554154396e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004321738803300705,
      "memory_efficiency": 0.11696775447428158
    },
    {
      "iter": 1,
      "ops_idx": 81,
      "module_name": "model.decoder.layers.7.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.386102884,
      "end_timestamp": 3093822.386126096,
      "duration_time": 2.321181818842888e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.00304331992506717
    },
    {
      "iter": 1,
      "ops_idx": 82,
      "module_name": "model.decoder.layers.7.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.386225274,
      "end_timestamp": 3093822.386288,
      "duration_time": 6.27259723842144e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0040206034135337335,
      "memory_efficiency": 0.10881753255275342
    },
    {
      "iter": 1,
      "ops_idx": 83,
      "module_name": "model.decoder.layers.8.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.386413501,
      "end_timestamp": 3093822.386447341,
      "duration_time": 3.384007140994072e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005871080429020039
    },
    {
      "iter": 1,
      "ops_idx": 84,
      "module_name": "model.decoder.layers.8.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.386527231,
      "end_timestamp": 3093822.386587298,
      "duration_time": 6.006704643368721e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.003148934486444426,
      "memory_efficiency": 0.08526258558293616
    },
    {
      "iter": 1,
      "ops_idx": 85,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093822.38675764,
      "end_timestamp": 3093822.38677492,
      "duration_time": 1.727975904941559e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010246808056705002
    },
    {
      "iter": 1,
      "ops_idx": 86,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093822.416142904,
      "end_timestamp": 3093822.416186446,
      "duration_time": 4.354165866971016e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 2.8281583246573673e-05,
      "memory_efficiency": 0.0020089591111700643
    },
    {
      "iter": 1,
      "ops_idx": 87,
      "module_name": "model.decoder.layers.8.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.386698132,
      "end_timestamp": 3093822.445607447,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 88,
      "module_name": "model.decoder.layers.8.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.445798194,
      "end_timestamp": 3093822.44587164,
      "duration_time": 7.344596087932587e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008584415523528988,
      "memory_efficiency": 0.023323869109279267
    },
    {
      "iter": 1,
      "ops_idx": 89,
      "module_name": "model.decoder.layers.8.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.44598595,
      "end_timestamp": 3093822.446023846,
      "duration_time": 3.789598122239113e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005242713727495549
    },
    {
      "iter": 1,
      "ops_idx": 90,
      "module_name": "model.decoder.layers.8.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.446107384,
      "end_timestamp": 3093822.446169447,
      "duration_time": 6.206333637237549e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004063530474288974,
      "memory_efficiency": 0.10997935239686032
    },
    {
      "iter": 1,
      "ops_idx": 91,
      "module_name": "model.decoder.layers.8.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.446267503,
      "end_timestamp": 3093822.44629122,
      "duration_time": 2.3717060685157776e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.002978488343375937
    },
    {
      "iter": 1,
      "ops_idx": 92,
      "module_name": "model.decoder.layers.8.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.446389262,
      "end_timestamp": 3093822.44645258,
      "duration_time": 6.331782788038254e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.00398302132476234,
      "memory_efficiency": 0.10780037424399917
    },
    {
      "iter": 1,
      "ops_idx": 93,
      "module_name": "model.decoder.layers.9.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.446576303,
      "end_timestamp": 3093822.446611126,
      "duration_time": 3.482308238744736e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005705347354407682
    },
    {
      "iter": 1,
      "ops_idx": 94,
      "module_name": "model.decoder.layers.9.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.446692254,
      "end_timestamp": 3093822.446750357,
      "duration_time": 5.8102887123823166e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0032553837404121484,
      "memory_efficiency": 0.08814487439070073
    },
    {
      "iter": 1,
      "ops_idx": 95,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093822.446924819,
      "end_timestamp": 3093822.44694175,
      "duration_time": 1.693097874522209e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010457893599059634
    },
    {
      "iter": 1,
      "ops_idx": 96,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093822.476416428,
      "end_timestamp": 3093822.476457194,
      "duration_time": 4.0765851736068726e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 3.0207317936933102e-05,
      "memory_efficiency": 0.0021457520982586685
    },
    {
      "iter": 1,
      "ops_idx": 97,
      "module_name": "model.decoder.layers.9.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.446866246,
      "end_timestamp": 3093822.505914976,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 98,
      "module_name": "model.decoder.layers.9.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.506102321,
      "end_timestamp": 3093822.506173041,
      "duration_time": 7.071997970342636e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008915311477138909,
      "memory_efficiency": 0.02422291388287327
    },
    {
      "iter": 1,
      "ops_idx": 99,
      "module_name": "model.decoder.layers.9.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.506287715,
      "end_timestamp": 3093822.506328888,
      "duration_time": 4.117283970117569e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0004825457326079704
    },
    {
      "iter": 1,
      "ops_idx": 100,
      "module_name": "model.decoder.layers.9.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.506402579,
      "end_timestamp": 3093822.506467028,
      "duration_time": 6.444891914725304e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.003913118513422646,
      "memory_efficiency": 0.10590845637344237
    },
    {
      "iter": 1,
      "ops_idx": 101,
      "module_name": "model.decoder.layers.9.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.506570895,
      "end_timestamp": 3093822.506594388,
      "duration_time": 2.3492611944675446e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0030069448623354458
    },
    {
      "iter": 1,
      "ops_idx": 102,
      "module_name": "model.decoder.layers.9.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.506689175,
      "end_timestamp": 3093822.506752804,
      "duration_time": 6.362888962030411e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.003963549579289197,
      "memory_efficiency": 0.1072733719314233
    },
    {
      "iter": 1,
      "ops_idx": 103,
      "module_name": "model.decoder.layers.10.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.506879324,
      "end_timestamp": 3093822.506914408,
      "duration_time": 3.508385270833969e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005662940801376594
    },
    {
      "iter": 1,
      "ops_idx": 104,
      "module_name": "model.decoder.layers.10.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.506996213,
      "end_timestamp": 3093822.507060778,
      "duration_time": 6.456486880779266e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0029295683164319727,
      "memory_efficiency": 0.07932288536840207
    },
    {
      "iter": 1,
      "ops_idx": 105,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093822.507228368,
      "end_timestamp": 3093822.50724549,
      "duration_time": 1.7121899873018265e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010341280790019016
    },
    {
      "iter": 1,
      "ops_idx": 106,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093822.536629796,
      "end_timestamp": 3093822.53666868,
      "duration_time": 3.888411447405815e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 3.1669154898277566e-05,
      "memory_efficiency": 0.0022495924899699035
    },
    {
      "iter": 1,
      "ops_idx": 107,
      "module_name": "model.decoder.layers.10.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.507172222,
      "end_timestamp": 3093822.56602526,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 108,
      "module_name": "model.decoder.layers.10.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.566216513,
      "end_timestamp": 3093822.566286668,
      "duration_time": 7.015513256192207e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008987092229588311,
      "memory_efficiency": 0.024417942288721822
    },
    {
      "iter": 1,
      "ops_idx": 109,
      "module_name": "model.decoder.layers.10.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.566398771,
      "end_timestamp": 3093822.566433451,
      "duration_time": 3.468012437224388e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005728865872538641
    },
    {
      "iter": 1,
      "ops_idx": 110,
      "module_name": "model.decoder.layers.10.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.566507277,
      "end_timestamp": 3093822.566565017,
      "duration_time": 5.774013698101044e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.00436778074787279,
      "memory_efficiency": 0.11821387857232124
    },
    {
      "iter": 1,
      "ops_idx": 111,
      "module_name": "model.decoder.layers.10.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.566663031,
      "end_timestamp": 3093822.566688698,
      "duration_time": 2.566678449511528e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.002752233681758073
    },
    {
      "iter": 1,
      "ops_idx": 112,
      "module_name": "model.decoder.layers.10.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.566800544,
      "end_timestamp": 3093822.566865844,
      "duration_time": 6.530014798045158e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0038621085324445697,
      "memory_efficiency": 0.1045278724921989
    },
    {
      "iter": 1,
      "ops_idx": 113,
      "module_name": "model.decoder.layers.11.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.566986009,
      "end_timestamp": 3093822.567020019,
      "duration_time": 3.4010037779808044e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.000584173949637597
    },
    {
      "iter": 1,
      "ops_idx": 114,
      "module_name": "model.decoder.layers.11.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.56709843,
      "end_timestamp": 3093822.567163324,
      "duration_time": 6.489409133791924e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0029147059480186125,
      "memory_efficiency": 0.0789204622744113
    },
    {
      "iter": 1,
      "ops_idx": 115,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093822.567331954,
      "end_timestamp": 3093822.567348972,
      "duration_time": 1.701805740594864e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010404382240688699
    },
    {
      "iter": 1,
      "ops_idx": 116,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093822.596724845,
      "end_timestamp": 3093822.596762777,
      "duration_time": 3.7931837141513824e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 3.2464207830671895e-05,
      "memory_efficiency": 0.0023060684240953236
    },
    {
      "iter": 1,
      "ops_idx": 117,
      "module_name": "model.decoder.layers.11.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.567274394,
      "end_timestamp": 3093822.626189542,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 118,
      "module_name": "model.decoder.layers.11.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.626372556,
      "end_timestamp": 3093822.626444531,
      "duration_time": 7.197493687272072e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008759863837434647,
      "memory_efficiency": 0.023800562426111754
    },
    {
      "iter": 1,
      "ops_idx": 119,
      "module_name": "model.decoder.layers.11.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.626615945,
      "end_timestamp": 3093822.626652543,
      "duration_time": 3.659818321466446e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005428624142521252
    },
    {
      "iter": 1,
      "ops_idx": 120,
      "module_name": "model.decoder.layers.11.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.626729534,
      "end_timestamp": 3093822.626791506,
      "duration_time": 6.197206676006317e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.00406951505525258,
      "memory_efficiency": 0.11014132493352728
    },
    {
      "iter": 1,
      "ops_idx": 121,
      "module_name": "model.decoder.layers.11.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.626893023,
      "end_timestamp": 3093822.626916239,
      "duration_time": 2.321600914001465e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003042770545266833
    },
    {
      "iter": 1,
      "ops_idx": 122,
      "module_name": "model.decoder.layers.11.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.627011187,
      "end_timestamp": 3093822.627077878,
      "duration_time": 6.66910782456398e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0037815591728220924,
      "memory_efficiency": 0.1023478060540822
    },
    {
      "iter": 1,
      "ops_idx": 123,
      "module_name": "model.decoder.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.627213461,
      "end_timestamp": 3093822.627249944,
      "duration_time": 3.648316487669945e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.000544573864803139
    },
    {
      "iter": 1,
      "ops_idx": 124,
      "module_name": "logits_processor",
      "operator_name": "LogitsProcessor",
      "input_shapes": [
        [],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "VocabParallelEmbedding",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          50272
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.62743756,
      "end_timestamp": 3093822.62752865,
      "duration_time": 9.109033271670341e-05,
      "ops_type": "TensorCore",
      "computes_ops": 617742336.0,
      "memory_byte": 77626112.0,
      "computes_efficiency": 0.0453076256120862,
      "memory_efficiency": 1.224760359953614
    },
    {
      "iter": 2,
      "ops_idx": 0,
      "module_name": "model.decoder.embed_tokens",
      "operator_name": "VocabParallelEmbedding",
      "input_shapes": [
        [
          4
        ]
      ],
      "input_dtypes": [
        "torch.int32"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.629427177,
      "end_timestamp": 3093822.629509338,
      "duration_time": 8.216127753257751e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12304.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0002152259901752061
    },
    {
      "iter": 2,
      "ops_idx": 1,
      "module_name": "lm_head",
      "operator_name": "VocabParallelEmbedding",
      "input_shapes": [
        [
          4
        ]
      ],
      "input_dtypes": [
        "torch.int32"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.629427177,
      "end_timestamp": 3093822.629587469,
      "duration_time": 0.00016029225662350655,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12304.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.00011031875577460488
    },
    {
      "iter": 2,
      "ops_idx": 2,
      "module_name": "model.decoder.embed_positions",
      "operator_name": "OPTLearnedPositionalEmbedding",
      "input_shapes": [
        [
          4
        ]
      ],
      "input_dtypes": [
        "torch.int64"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.629657676,
      "end_timestamp": 3093822.629717223,
      "duration_time": 5.9546902775764465e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0002973494270763937
    },
    {
      "iter": 2,
      "ops_idx": 3,
      "module_name": "model.decoder.layers.0.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.62982018,
      "end_timestamp": 3093822.629862903,
      "duration_time": 4.2723026126623154e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.00046503677052908026
    },
    {
      "iter": 2,
      "ops_idx": 4,
      "module_name": "model.decoder.layers.0.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.629944533,
      "end_timestamp": 3093822.630017589,
      "duration_time": 7.305573672056198e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.002589080645882525,
      "memory_efficiency": 0.07010362111405533
    },
    {
      "iter": 2,
      "ops_idx": 5,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093822.630202215,
      "end_timestamp": 3093822.630220481,
      "duration_time": 1.826602965593338e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0009693533711523204
    },
    {
      "iter": 2,
      "ops_idx": 6,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093822.659627831,
      "end_timestamp": 3093822.659673552,
      "duration_time": 4.572095349431038e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.052467654937435e-05,
      "memory_efficiency": 0.0021425446362499777
    },
    {
      "iter": 2,
      "ops_idx": 7,
      "module_name": "model.decoder.layers.0.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.63013561,
      "end_timestamp": 3093822.689127393,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 8,
      "module_name": "model.decoder.layers.0.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.68931384,
      "end_timestamp": 3093822.689388687,
      "duration_time": 7.484667003154755e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008423763494718452,
      "memory_efficiency": 0.02288737731996095
    },
    {
      "iter": 2,
      "ops_idx": 9,
      "module_name": "model.decoder.layers.0.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.689511119,
      "end_timestamp": 3093822.689550632,
      "duration_time": 3.951322287321091e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005028134040320024
    },
    {
      "iter": 2,
      "ops_idx": 10,
      "module_name": "model.decoder.layers.0.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.689628363,
      "end_timestamp": 3093822.689689552,
      "duration_time": 6.118882447481155e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004121606532725791,
      "memory_efficiency": 0.1115511794908262
    },
    {
      "iter": 2,
      "ops_idx": 11,
      "module_name": "model.decoder.layers.0.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.689785921,
      "end_timestamp": 3093822.689809221,
      "duration_time": 2.329982817173004e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0030318244524906715
    },
    {
      "iter": 2,
      "ops_idx": 12,
      "module_name": "model.decoder.layers.0.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.689908303,
      "end_timestamp": 3093822.689972862,
      "duration_time": 6.455928087234497e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.003906429180707115,
      "memory_efficiency": 0.10572740974793382
    },
    {
      "iter": 2,
      "ops_idx": 13,
      "module_name": "model.decoder.layers.1.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.690099563,
      "end_timestamp": 3093822.69013612,
      "duration_time": 3.655720502138138e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005434709268811496
    },
    {
      "iter": 2,
      "ops_idx": 14,
      "module_name": "model.decoder.layers.1.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.690222447,
      "end_timestamp": 3093822.690282665,
      "duration_time": 6.0218386352062225e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.00314102063293529,
      "memory_efficiency": 0.08504830496991667
    },
    {
      "iter": 2,
      "ops_idx": 15,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093822.690452804,
      "end_timestamp": 3093822.690470042,
      "duration_time": 1.72383151948452e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010271443133747784
    },
    {
      "iter": 2,
      "ops_idx": 16,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093822.71978909,
      "end_timestamp": 3093822.719828454,
      "duration_time": 3.936374559998512e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.545438310482676e-05,
      "memory_efficiency": 0.0024885635800244174
    },
    {
      "iter": 2,
      "ops_idx": 17,
      "module_name": "model.decoder.layers.1.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.690392949,
      "end_timestamp": 3093822.749204097,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 18,
      "module_name": "model.decoder.layers.1.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.749387762,
      "end_timestamp": 3093822.749459009,
      "duration_time": 7.124710828065872e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008849350688442544,
      "memory_efficiency": 0.02404369832676673
    },
    {
      "iter": 2,
      "ops_idx": 19,
      "module_name": "model.decoder.layers.1.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.749576844,
      "end_timestamp": 3093822.749612832,
      "duration_time": 3.598816692829132e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005520641864516786
    },
    {
      "iter": 2,
      "ops_idx": 20,
      "module_name": "model.decoder.layers.1.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.749687703,
      "end_timestamp": 3093822.749749508,
      "duration_time": 6.1805360019207e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004080491701800961,
      "memory_efficiency": 0.11043840760253111
    },
    {
      "iter": 2,
      "ops_idx": 21,
      "module_name": "model.decoder.layers.1.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.749849524,
      "end_timestamp": 3093822.74987178,
      "duration_time": 2.2256281226873398e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003173979878749309
    },
    {
      "iter": 2,
      "ops_idx": 22,
      "module_name": "model.decoder.layers.1.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.749967905,
      "end_timestamp": 3093822.750031658,
      "duration_time": 6.375275552272797e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.00395584875692607,
      "memory_efficiency": 0.10706494936346703
    },
    {
      "iter": 2,
      "ops_idx": 23,
      "module_name": "model.decoder.layers.2.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.750156344,
      "end_timestamp": 3093822.750189995,
      "duration_time": 3.365101292729378e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005904065396212763
    },
    {
      "iter": 2,
      "ops_idx": 24,
      "module_name": "model.decoder.layers.2.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.750272935,
      "end_timestamp": 3093822.750332666,
      "duration_time": 5.973130464553833e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.003166634232021999,
      "memory_efficiency": 0.08574183533506675
    },
    {
      "iter": 2,
      "ops_idx": 25,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093822.750501263,
      "end_timestamp": 3093822.750518167,
      "duration_time": 1.6903970390558243e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010474602720812352
    },
    {
      "iter": 2,
      "ops_idx": 26,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093822.779909096,
      "end_timestamp": 3093822.779949786,
      "duration_time": 4.0689948946237564e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.429882202080911e-05,
      "memory_efficiency": 0.002407454081667686
    },
    {
      "iter": 2,
      "ops_idx": 27,
      "module_name": "model.decoder.layers.2.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.750444477,
      "end_timestamp": 3093822.809568805,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 28,
      "module_name": "model.decoder.layers.2.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.809761011,
      "end_timestamp": 3093822.809837109,
      "duration_time": 7.609790191054344e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008285256634987891,
      "memory_efficiency": 0.022511053986329396
    },
    {
      "iter": 2,
      "ops_idx": 29,
      "module_name": "model.decoder.layers.2.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.80995712,
      "end_timestamp": 3093822.809993999,
      "duration_time": 3.6878976970911026e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005387291006696154
    },
    {
      "iter": 2,
      "ops_idx": 30,
      "module_name": "model.decoder.layers.2.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.810069762,
      "end_timestamp": 3093822.810131072,
      "duration_time": 6.130989640951157e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004113467375653069,
      "memory_efficiency": 0.11133089340472987
    },
    {
      "iter": 2,
      "ops_idx": 31,
      "module_name": "model.decoder.layers.2.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.810229163,
      "end_timestamp": 3093822.810252766,
      "duration_time": 2.360297366976738e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0029928851244860268
    },
    {
      "iter": 2,
      "ops_idx": 32,
      "module_name": "model.decoder.layers.2.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.810355265,
      "end_timestamp": 3093822.810424703,
      "duration_time": 6.943801417946815e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0036319624295904187,
      "memory_efficiency": 0.09829897387590647
    },
    {
      "iter": 2,
      "ops_idx": 33,
      "module_name": "model.decoder.layers.3.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.810547492,
      "end_timestamp": 3093822.810581955,
      "duration_time": 3.4463126212358475e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005764937856981115
    },
    {
      "iter": 2,
      "ops_idx": 34,
      "module_name": "model.decoder.layers.3.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.810664217,
      "end_timestamp": 3093822.810723611,
      "duration_time": 5.939416587352753e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0031846089802264705,
      "memory_efficiency": 0.0862285312360812
    },
    {
      "iter": 2,
      "ops_idx": 35,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093822.810896089,
      "end_timestamp": 3093822.810913362,
      "duration_time": 1.727323979139328e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010250675402173107
    },
    {
      "iter": 2,
      "ops_idx": 36,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093822.840590993,
      "end_timestamp": 3093822.840629341,
      "duration_time": 3.834813833236694e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.639335252331845e-05,
      "memory_efficiency": 0.002554470384571159
    },
    {
      "iter": 2,
      "ops_idx": 37,
      "module_name": "model.decoder.layers.3.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.81083555,
      "end_timestamp": 3093822.870336865,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 38,
      "module_name": "model.decoder.layers.3.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.870534105,
      "end_timestamp": 3093822.870605872,
      "duration_time": 7.176678627729416e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008785270727838969,
      "memory_efficiency": 0.023869592983246365
    },
    {
      "iter": 2,
      "ops_idx": 39,
      "module_name": "model.decoder.layers.3.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.870723197,
      "end_timestamp": 3093822.870757842,
      "duration_time": 3.46451997756958e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.000573464093894241
    },
    {
      "iter": 2,
      "ops_idx": 40,
      "module_name": "model.decoder.layers.3.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.870831391,
      "end_timestamp": 3093822.870889779,
      "duration_time": 5.838833749294281e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004319291651619249,
      "memory_efficiency": 0.1169015223741789
    },
    {
      "iter": 2,
      "ops_idx": 41,
      "module_name": "model.decoder.layers.3.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.870985844,
      "end_timestamp": 3093822.871008126,
      "duration_time": 2.2281892597675323e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0031703316260151145
    },
    {
      "iter": 2,
      "ops_idx": 42,
      "module_name": "model.decoder.layers.3.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.871107461,
      "end_timestamp": 3093822.871170611,
      "duration_time": 6.315018981695175e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.003993594626021166,
      "memory_efficiency": 0.10808654038265625
    },
    {
      "iter": 2,
      "ops_idx": 43,
      "module_name": "model.decoder.layers.4.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.871300793,
      "end_timestamp": 3093822.871334553,
      "duration_time": 3.3760443329811096e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005884928080790555
    },
    {
      "iter": 2,
      "ops_idx": 44,
      "module_name": "model.decoder.layers.4.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.871417863,
      "end_timestamp": 3093822.871476562,
      "duration_time": 5.869939923286438e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.003222302042028351,
      "memory_efficiency": 0.08724913294170594
    },
    {
      "iter": 2,
      "ops_idx": 45,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093822.871640619,
      "end_timestamp": 3093822.871657449,
      "duration_time": 1.6829930245876312e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.001052068378529714
    },
    {
      "iter": 2,
      "ops_idx": 46,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093822.901290983,
      "end_timestamp": 3093822.901329407,
      "duration_time": 3.8424041122198105e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.632146115252161e-05,
      "memory_efficiency": 0.002549424287828929
    },
    {
      "iter": 2,
      "ops_idx": 47,
      "module_name": "model.decoder.layers.4.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.871582797,
      "end_timestamp": 3093822.930726437,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 48,
      "module_name": "model.decoder.layers.4.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.93091535,
      "end_timestamp": 3093822.930985291,
      "duration_time": 6.994092836976051e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0009014616497220891,
      "memory_efficiency": 0.024492725762777973
    },
    {
      "iter": 2,
      "ops_idx": 49,
      "module_name": "model.decoder.layers.4.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.931096805,
      "end_timestamp": 3093822.931131417,
      "duration_time": 3.461213782429695e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005740118740428571
    },
    {
      "iter": 2,
      "ops_idx": 50,
      "module_name": "model.decoder.layers.4.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.931210579,
      "end_timestamp": 3093822.931270082,
      "duration_time": 5.950313061475754e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004238369579543554,
      "memory_efficiency": 0.11471136848267788
    },
    {
      "iter": 2,
      "ops_idx": 51,
      "module_name": "model.decoder.layers.4.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.931370528,
      "end_timestamp": 3093822.931393016,
      "duration_time": 2.2488180547952652e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0031412496284103954
    },
    {
      "iter": 2,
      "ops_idx": 52,
      "module_name": "model.decoder.layers.4.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.931487967,
      "end_timestamp": 3093822.931551167,
      "duration_time": 6.320001557469368e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0039904461477091565,
      "memory_efficiency": 0.10800132689453765
    },
    {
      "iter": 2,
      "ops_idx": 53,
      "module_name": "model.decoder.layers.5.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.931671405,
      "end_timestamp": 3093822.931705676,
      "duration_time": 3.427080810070038e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005797289062684321
    },
    {
      "iter": 2,
      "ops_idx": 54,
      "module_name": "model.decoder.layers.5.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.931792138,
      "end_timestamp": 3093822.931851706,
      "duration_time": 5.9567857533693314e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0031753230994905125,
      "memory_efficiency": 0.08597710072700873
    },
    {
      "iter": 2,
      "ops_idx": 55,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093822.932029891,
      "end_timestamp": 3093822.932047258,
      "duration_time": 1.7367303371429443e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010195156407341516
    },
    {
      "iter": 2,
      "ops_idx": 56,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093822.961428007,
      "end_timestamp": 3093822.961466306,
      "duration_time": 3.829877823591232e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.644025687571822e-05,
      "memory_efficiency": 0.002557762628093817
    },
    {
      "iter": 2,
      "ops_idx": 57,
      "module_name": "model.decoder.layers.5.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.931963787,
      "end_timestamp": 3093822.990972035,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 58,
      "module_name": "model.decoder.layers.5.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.991159567,
      "end_timestamp": 3093822.99123345,
      "duration_time": 7.388275116682053e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008533664986153497,
      "memory_efficiency": 0.0231859798275073
    },
    {
      "iter": 2,
      "ops_idx": 59,
      "module_name": "model.decoder.layers.5.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.991353684,
      "end_timestamp": 3093822.991389804,
      "duration_time": 3.611994907259941e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005500500030390698
    },
    {
      "iter": 2,
      "ops_idx": 60,
      "module_name": "model.decoder.layers.5.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.991469587,
      "end_timestamp": 3093822.991531126,
      "duration_time": 6.153900176286697e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004098153227395572,
      "memory_efficiency": 0.11091641635859334
    },
    {
      "iter": 2,
      "ops_idx": 61,
      "module_name": "model.decoder.layers.5.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.99162976,
      "end_timestamp": 3093822.991653116,
      "duration_time": 2.3356173187494278e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0030245104034296953
    },
    {
      "iter": 2,
      "ops_idx": 62,
      "module_name": "model.decoder.layers.5.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.991753995,
      "end_timestamp": 3093822.991818823,
      "duration_time": 6.482796743512154e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0038902385600410472,
      "memory_efficiency": 0.10528921099760477
    },
    {
      "iter": 2,
      "ops_idx": 63,
      "module_name": "model.decoder.layers.6.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.991942461,
      "end_timestamp": 3093822.991976085,
      "duration_time": 3.362400457262993e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.000590880781444064
    },
    {
      "iter": 2,
      "ops_idx": 64,
      "module_name": "model.decoder.layers.6.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093822.992065816,
      "end_timestamp": 3093822.992127585,
      "duration_time": 6.1769038438797e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.003062168341851561,
      "memory_efficiency": 0.08291324936749656
    },
    {
      "iter": 2,
      "ops_idx": 65,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093822.992292627,
      "end_timestamp": 3093822.992309951,
      "duration_time": 1.7323996871709824e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.001022064224305054
    },
    {
      "iter": 2,
      "ops_idx": 66,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093823.02168181,
      "end_timestamp": 3093823.021720725,
      "duration_time": 3.891531378030777e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.586293367237431e-05,
      "memory_efficiency": 0.002517239979779874
    },
    {
      "iter": 2,
      "ops_idx": 67,
      "module_name": "model.decoder.layers.6.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093822.992236272,
      "end_timestamp": 3093823.051178075,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 68,
      "module_name": "model.decoder.layers.6.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.051361242,
      "end_timestamp": 3093823.051432589,
      "duration_time": 7.134722545742989e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.000883693293846692,
      "memory_efficiency": 0.024009959282533685
    },
    {
      "iter": 2,
      "ops_idx": 69,
      "module_name": "model.decoder.layers.6.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.051548259,
      "end_timestamp": 3093823.051583609,
      "duration_time": 3.535021096467972e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005620271436853746
    },
    {
      "iter": 2,
      "ops_idx": 70,
      "module_name": "model.decoder.layers.6.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.051661673,
      "end_timestamp": 3093823.051721415,
      "duration_time": 5.974201485514641e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004221422047727771,
      "memory_efficiency": 0.11425268395068822
    },
    {
      "iter": 2,
      "ops_idx": 71,
      "module_name": "model.decoder.layers.6.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.051817574,
      "end_timestamp": 3093823.051840489,
      "duration_time": 2.291472628712654e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0030827768966006875
    },
    {
      "iter": 2,
      "ops_idx": 72,
      "module_name": "model.decoder.layers.6.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.051938252,
      "end_timestamp": 3093823.052007991,
      "duration_time": 6.973883137106895e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0036162960251412864,
      "memory_efficiency": 0.0978749630246025
    },
    {
      "iter": 2,
      "ops_idx": 73,
      "module_name": "model.decoder.layers.7.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.052137555,
      "end_timestamp": 3093823.052171583,
      "duration_time": 3.402773290872574e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005838701670324812
    },
    {
      "iter": 2,
      "ops_idx": 74,
      "module_name": "model.decoder.layers.7.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.052251617,
      "end_timestamp": 3093823.052313943,
      "duration_time": 6.232596933841705e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0030348054915418387,
      "memory_efficiency": 0.08217235514554021
    },
    {
      "iter": 2,
      "ops_idx": 75,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093823.052480969,
      "end_timestamp": 3093823.052497769,
      "duration_time": 1.679966226220131e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010539638921423877
    },
    {
      "iter": 2,
      "ops_idx": 76,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093823.08181686,
      "end_timestamp": 3093823.081855741,
      "duration_time": 3.8880854845047e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.5894717914634484e-05,
      "memory_efficiency": 0.0025194709340591653
    },
    {
      "iter": 2,
      "ops_idx": 77,
      "module_name": "model.decoder.layers.7.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.052421109,
      "end_timestamp": 3093823.111171358,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 78,
      "module_name": "model.decoder.layers.7.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.111356194,
      "end_timestamp": 3093823.111426422,
      "duration_time": 7.022777572274208e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008977796039022406,
      "memory_efficiency": 0.024392684525816496
    },
    {
      "iter": 2,
      "ops_idx": 79,
      "module_name": "model.decoder.layers.7.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.111541448,
      "end_timestamp": 3093823.111575919,
      "duration_time": 3.4471042454242706e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005763613944523752
    },
    {
      "iter": 2,
      "ops_idx": 80,
      "module_name": "model.decoder.layers.7.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.111653879,
      "end_timestamp": 3093823.111713254,
      "duration_time": 5.937507376074791e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004247510659126436,
      "memory_efficiency": 0.1149587715768824
    },
    {
      "iter": 2,
      "ops_idx": 81,
      "module_name": "model.decoder.layers.7.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.1118083,
      "end_timestamp": 3093823.111831111,
      "duration_time": 2.2810883820056915e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0030968106868252813
    },
    {
      "iter": 2,
      "ops_idx": 82,
      "module_name": "model.decoder.layers.7.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.111928266,
      "end_timestamp": 3093823.111995686,
      "duration_time": 6.741983816027641e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0037406832405270955,
      "memory_efficiency": 0.10124149995133092
    },
    {
      "iter": 2,
      "ops_idx": 83,
      "module_name": "model.decoder.layers.8.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.112130028,
      "end_timestamp": 3093823.112164666,
      "duration_time": 3.463774919509888e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005735874460331728
    },
    {
      "iter": 2,
      "ops_idx": 84,
      "module_name": "model.decoder.layers.8.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.112244086,
      "end_timestamp": 3093823.11230432,
      "duration_time": 6.023421883583069e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.003140195019867693,
      "memory_efficiency": 0.08502595013683348
    },
    {
      "iter": 2,
      "ops_idx": 85,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093823.112475995,
      "end_timestamp": 3093823.112492438,
      "duration_time": 1.644296571612358e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010768274853960784
    },
    {
      "iter": 2,
      "ops_idx": 86,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093823.141734752,
      "end_timestamp": 3093823.141772503,
      "duration_time": 3.775116056203842e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.6968858603679795e-05,
      "memory_efficiency": 0.0025948654879758737
    },
    {
      "iter": 2,
      "ops_idx": 87,
      "module_name": "model.decoder.layers.8.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.112420517,
      "end_timestamp": 3093823.17103334,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 88,
      "module_name": "model.decoder.layers.8.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.17121695,
      "end_timestamp": 3093823.171285724,
      "duration_time": 6.877398118376732e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0009167575235004748,
      "memory_efficiency": 0.024908314869504327
    },
    {
      "iter": 2,
      "ops_idx": 89,
      "module_name": "model.decoder.layers.8.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.171397999,
      "end_timestamp": 3093823.171432597,
      "duration_time": 3.459816798567772e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.000574243645079093
    },
    {
      "iter": 2,
      "ops_idx": 90,
      "module_name": "model.decoder.layers.8.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.171555809,
      "end_timestamp": 3093823.17162333,
      "duration_time": 6.752088665962219e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.003735085114574031,
      "memory_efficiency": 0.10108998681002444
    },
    {
      "iter": 2,
      "ops_idx": 91,
      "module_name": "model.decoder.layers.8.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.171727138,
      "end_timestamp": 3093823.171750422,
      "duration_time": 2.328399568796158e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0030338860106560385
    },
    {
      "iter": 2,
      "ops_idx": 92,
      "module_name": "model.decoder.layers.8.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.171849452,
      "end_timestamp": 3093823.171915055,
      "duration_time": 6.560282781720161e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.00384428944721598,
      "memory_efficiency": 0.10404559938851615
    },
    {
      "iter": 2,
      "ops_idx": 93,
      "module_name": "model.decoder.layers.9.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.172047394,
      "end_timestamp": 3093823.172081224,
      "duration_time": 3.383029252290726e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005872777506638889
    },
    {
      "iter": 2,
      "ops_idx": 94,
      "module_name": "model.decoder.layers.9.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.172167108,
      "end_timestamp": 3093823.172227577,
      "duration_time": 6.046891212463379e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.003128007225002509,
      "memory_efficiency": 0.08469594552504069
    },
    {
      "iter": 2,
      "ops_idx": 95,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093823.172390335,
      "end_timestamp": 3093823.172407349,
      "duration_time": 1.7014332115650177e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010406660281575598
    },
    {
      "iter": 2,
      "ops_idx": 96,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093823.201729257,
      "end_timestamp": 3093823.201771819,
      "duration_time": 4.2561907321214676e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.2790290773627435e-05,
      "memory_efficiency": 0.002301569404166301
    },
    {
      "iter": 2,
      "ops_idx": 97,
      "module_name": "model.decoder.layers.9.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.172335621,
      "end_timestamp": 3093823.231139887,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 98,
      "module_name": "model.decoder.layers.9.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.231327971,
      "end_timestamp": 3093823.231398165,
      "duration_time": 7.019424811005592e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008982084197617676,
      "memory_efficiency": 0.024404335458780048
    },
    {
      "iter": 2,
      "ops_idx": 99,
      "module_name": "model.decoder.layers.9.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.231509137,
      "end_timestamp": 3093823.231543669,
      "duration_time": 3.453204408288002e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005753432391511459
    },
    {
      "iter": 2,
      "ops_idx": 100,
      "module_name": "model.decoder.layers.9.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.231617882,
      "end_timestamp": 3093823.231676231,
      "duration_time": 5.834922194480896e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004322187173699438,
      "memory_efficiency": 0.11697988960810145
    },
    {
      "iter": 2,
      "ops_idx": 101,
      "module_name": "model.decoder.layers.9.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.231774389,
      "end_timestamp": 3093823.23179692,
      "duration_time": 2.2531021386384964e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0031352768069613153
    },
    {
      "iter": 2,
      "ops_idx": 102,
      "module_name": "model.decoder.layers.9.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.231897754,
      "end_timestamp": 3093823.231966166,
      "duration_time": 6.84116967022419e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0036864494062011834,
      "memory_efficiency": 0.09977366255847708
    },
    {
      "iter": 2,
      "ops_idx": 103,
      "module_name": "model.decoder.layers.10.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.2321108,
      "end_timestamp": 3093823.232146028,
      "duration_time": 3.522774204611778e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005639810258388062
    },
    {
      "iter": 2,
      "ops_idx": 104,
      "module_name": "model.decoder.layers.10.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.232227672,
      "end_timestamp": 3093823.23228865,
      "duration_time": 6.097787991166115e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.003101898496436978,
      "memory_efficiency": 0.0839890087140771
    },
    {
      "iter": 2,
      "ops_idx": 105,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093823.23245354,
      "end_timestamp": 3093823.232470059,
      "duration_time": 1.6518868505954742e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010718795550775475
    },
    {
      "iter": 2,
      "ops_idx": 106,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093823.261835284,
      "end_timestamp": 3093823.261874434,
      "duration_time": 3.915000706911087e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.564794546471348e-05,
      "memory_efficiency": 0.0025021498336013997
    },
    {
      "iter": 2,
      "ops_idx": 107,
      "module_name": "model.decoder.layers.10.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.232400172,
      "end_timestamp": 3093823.291199581,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 108,
      "module_name": "model.decoder.layers.10.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.291383845,
      "end_timestamp": 3093823.291461351,
      "duration_time": 7.750606164336205e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008134726927735538,
      "memory_efficiency": 0.022102064558989946
    },
    {
      "iter": 2,
      "ops_idx": 109,
      "module_name": "model.decoder.layers.10.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.291571705,
      "end_timestamp": 3093823.291606469,
      "duration_time": 3.4763943403959274e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005715053055486106
    },
    {
      "iter": 2,
      "ops_idx": 110,
      "module_name": "model.decoder.layers.10.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.291687768,
      "end_timestamp": 3093823.291747851,
      "duration_time": 6.008287891745567e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004197472944525056,
      "memory_efficiency": 0.11360450206122397
    },
    {
      "iter": 2,
      "ops_idx": 111,
      "module_name": "model.decoder.layers.10.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.291845198,
      "end_timestamp": 3093823.291867588,
      "duration_time": 2.2390391677618027e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003154968872674817
    },
    {
      "iter": 2,
      "ops_idx": 112,
      "module_name": "model.decoder.layers.10.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.291961875,
      "end_timestamp": 3093823.292036584,
      "duration_time": 7.470929995179176e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.003375701001721763,
      "memory_efficiency": 0.09136326463006379
    },
    {
      "iter": 2,
      "ops_idx": 113,
      "module_name": "model.decoder.layers.11.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.29216041,
      "end_timestamp": 3093823.292193801,
      "duration_time": 3.339117392897606e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005950008867437144
    },
    {
      "iter": 2,
      "ops_idx": 114,
      "module_name": "model.decoder.layers.11.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.292276575,
      "end_timestamp": 3093823.292337431,
      "duration_time": 6.085587665438652e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0031081171517436763,
      "memory_efficiency": 0.08415738904481458
    },
    {
      "iter": 2,
      "ops_idx": 115,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3093823.2925084,
      "end_timestamp": 3093823.292527376,
      "duration_time": 1.8976163119077682e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0009330778468459896
    },
    {
      "iter": 2,
      "ops_idx": 116,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3093823.322133402,
      "end_timestamp": 3093823.322172321,
      "duration_time": 3.891903907060623e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.585950090933405e-05,
      "memory_efficiency": 0.002516999032164015
    },
    {
      "iter": 2,
      "ops_idx": 117,
      "module_name": "model.decoder.layers.11.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.292450394,
      "end_timestamp": 3093823.351799174,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 118,
      "module_name": "model.decoder.layers.11.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.351985081,
      "end_timestamp": 3093823.352064581,
      "duration_time": 7.950002327561378e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0007930697636743805,
      "memory_efficiency": 0.021547716687022777
    },
    {
      "iter": 2,
      "ops_idx": 119,
      "module_name": "model.decoder.layers.11.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.352177124,
      "end_timestamp": 3093823.352211124,
      "duration_time": 3.3999793231487274e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005843499683037709
    },
    {
      "iter": 2,
      "ops_idx": 120,
      "module_name": "model.decoder.layers.11.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.352291294,
      "end_timestamp": 3093823.352353022,
      "duration_time": 6.172806024551392e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004085601551095613,
      "memory_efficiency": 0.11057670554808045
    },
    {
      "iter": 2,
      "ops_idx": 121,
      "module_name": "model.decoder.layers.11.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.352447664,
      "end_timestamp": 3093823.35246991,
      "duration_time": 2.2246036678552628e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0031754415319285626
    },
    {
      "iter": 2,
      "ops_idx": 122,
      "module_name": "model.decoder.layers.11.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3093823.352569872,
      "end_timestamp": 3093823.352633142,
      "duration_time": 6.326986476778984e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.003986040741683174,
      "memory_efficiency": 0.10788209468873818
    },
    {
      "iter": 2,
      "ops_idx": 123,
      "module_name": "model.decoder.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.352820667,
      "end_timestamp": 3093823.35285689,
      "duration_time": 3.622286021709442e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005484872806310938
    },
    {
      "iter": 2,
      "ops_idx": 124,
      "module_name": "logits_processor",
      "operator_name": "LogitsProcessor",
      "input_shapes": [
        [],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "VocabParallelEmbedding",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          50272
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3093823.353040614,
      "end_timestamp": 3093823.353127052,
      "duration_time": 8.643791079521179e-05,
      "ops_type": "TensorCore",
      "computes_ops": 617742336.0,
      "memory_byte": 77626112.0,
      "computes_efficiency": 0.04774625686391976,
      "memory_efficiency": 1.2906816888566468
    }
  ]
}