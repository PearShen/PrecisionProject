{
  "framework": "vllm",
  "model_name": "facebook/opt-125m",
  "model_type": "vLLM",
  "parameters": "N/A",
  "input_info": {
    "type": "text_or_sampling_params",
    "sample_input": "{'prompts': ['Hello, my name is', 'The president of the United States is', 'The capital of France is', 'The future of AI is'], 'params': {'temperature': 0.0, 'max_tokens': 3}}"
  },
  "output_info": {
    "type": "generated_text",
    "sample_output": "[' J.C', ' not a racist', ' the capital of', ' in the hands']",
    "num_outputs": 4
  },
  "layers": [
    {
      "iter": 0,
      "ops_idx": 0,
      "module_name": "model.decoder.embed_tokens",
      "operator_name": "VocabParallelEmbedding",
      "input_shapes": [
        [
          26
        ]
      ],
      "input_dtypes": [
        "torch.int32"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.220540061,
      "end_timestamp": 3191210.22066726,
      "duration_time": 0.00012719864025712013,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 79976.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0009036344633025582
    },
    {
      "iter": 0,
      "ops_idx": 1,
      "module_name": "lm_head",
      "operator_name": "VocabParallelEmbedding",
      "input_shapes": [
        [
          26
        ]
      ],
      "input_dtypes": [
        "torch.int32"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.220540061,
      "end_timestamp": 3191210.220814126,
      "duration_time": 0.00027406495064496994,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 79976.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0004193935589029596
    },
    {
      "iter": 0,
      "ops_idx": 2,
      "module_name": "model.decoder.embed_positions",
      "operator_name": "OPTLearnedPositionalEmbedding",
      "input_shapes": [
        [
          26
        ]
      ],
      "input_dtypes": [
        "torch.int64"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.220893263,
      "end_timestamp": 3191210.220970956,
      "duration_time": 7.769325748085976e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0014813453186450659
    },
    {
      "iter": 0,
      "ops_idx": 3,
      "module_name": "model.decoder.layers.0.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.221081811,
      "end_timestamp": 3191210.221136345,
      "duration_time": 5.453405901789665e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0021454324103189577
    },
    {
      "iter": 0,
      "ops_idx": 4,
      "module_name": "model.decoder.layers.0.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.221229029,
      "end_timestamp": 3191210.22180818,
      "duration_time": 0.0005791513249278069,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.0021228592738583166,
      "memory_efficiency": 0.009178489589229993
    },
    {
      "iter": 0,
      "ops_idx": 5,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191210.222091982,
      "end_timestamp": 3191210.223067145,
      "duration_time": 0.0009751627221703529,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.00011802188562274837
    },
    {
      "iter": 0,
      "ops_idx": 6,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191210.254466678,
      "end_timestamp": 3191210.256999845,
      "duration_time": 0.0025331671349704266,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 2.7870966836490376e-06,
      "memory_efficiency": 4.956377263317956e-05
    },
    {
      "iter": 0,
      "ops_idx": 7,
      "module_name": "model.decoder.layers.0.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.22198004,
      "end_timestamp": 3191210.288305693,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 8,
      "module_name": "model.decoder.layers.0.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.288502336,
      "end_timestamp": 3191210.288669307,
      "duration_time": 0.00016697077080607414,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.0024544350989396846,
      "memory_efficiency": 0.01084127077453055
    },
    {
      "iter": 0,
      "ops_idx": 9,
      "module_name": "model.decoder.layers.0.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.288805486,
      "end_timestamp": 3191210.288856373,
      "duration_time": 5.088699981570244e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.00229919504209284
    },
    {
      "iter": 0,
      "ops_idx": 10,
      "module_name": "model.decoder.layers.0.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.288938805,
      "end_timestamp": 3191210.289046182,
      "duration_time": 0.0001073768362402916,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.015266567155930541,
      "memory_efficiency": 0.06582903900213094
    },
    {
      "iter": 0,
      "ops_idx": 11,
      "module_name": "model.decoder.layers.0.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.289166977,
      "end_timestamp": 3191210.289202414,
      "duration_time": 3.543682396411896e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.012957324493841668
    },
    {
      "iter": 0,
      "ops_idx": 12,
      "module_name": "model.decoder.layers.0.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.289307588,
      "end_timestamp": 3191210.299431997,
      "duration_time": 0.010124409105628729,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.00016191322025325925,
      "memory_efficiency": 0.0006981655785578437
    },
    {
      "iter": 0,
      "ops_idx": 13,
      "module_name": "model.decoder.layers.1.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.299714318,
      "end_timestamp": 3191210.299757763,
      "duration_time": 4.344480112195015e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0026930526705560036
    },
    {
      "iter": 0,
      "ops_idx": 14,
      "module_name": "model.decoder.layers.1.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.299891809,
      "end_timestamp": 3191210.29998152,
      "duration_time": 8.971104398369789e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.013704631074338412,
      "memory_efficiency": 0.05925395771121108
    },
    {
      "iter": 0,
      "ops_idx": 15,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191210.300303553,
      "end_timestamp": 3191210.300328036,
      "duration_time": 2.44826078414917e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.004700910295369294
    },
    {
      "iter": 0,
      "ops_idx": 16,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191210.331286153,
      "end_timestamp": 3191210.3313394,
      "duration_time": 5.324697121977806e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.0001325931139231141,
      "memory_efficiency": 0.0023579429410415286
    },
    {
      "iter": 0,
      "ops_idx": 17,
      "module_name": "model.decoder.layers.1.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.300220837,
      "end_timestamp": 3191210.362538938,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 18,
      "module_name": "model.decoder.layers.1.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.362828993,
      "end_timestamp": 3191210.362922657,
      "duration_time": 9.366404265165329e-05,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.004375413539298137,
      "memory_efficiency": 0.019326256762939094
    },
    {
      "iter": 0,
      "ops_idx": 19,
      "module_name": "model.decoder.layers.1.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.363101882,
      "end_timestamp": 3191210.363144221,
      "duration_time": 4.233885556459427e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0027633986824405917
    },
    {
      "iter": 0,
      "ops_idx": 20,
      "module_name": "model.decoder.layers.1.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.363282489,
      "end_timestamp": 3191210.363360559,
      "duration_time": 7.806997746229172e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.020997517032018465,
      "memory_efficiency": 0.09054074524616994
    },
    {
      "iter": 0,
      "ops_idx": 21,
      "module_name": "model.decoder.layers.1.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.363586993,
      "end_timestamp": 3191210.363620959,
      "duration_time": 3.396626561880112e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.013518307614013202
    },
    {
      "iter": 0,
      "ops_idx": 22,
      "module_name": "model.decoder.layers.1.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.36390235,
      "end_timestamp": 3191210.363990196,
      "duration_time": 8.78460705280304e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.018660774142773968,
      "memory_efficiency": 0.08046477091462075
    },
    {
      "iter": 0,
      "ops_idx": 23,
      "module_name": "model.decoder.layers.2.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.364256782,
      "end_timestamp": 3191210.364293463,
      "duration_time": 3.668107092380524e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0031896325471596947
    },
    {
      "iter": 0,
      "ops_idx": 24,
      "module_name": "model.decoder.layers.2.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.364496883,
      "end_timestamp": 3191210.36457962,
      "duration_time": 8.273683488368988e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.014859847646077793,
      "memory_efficiency": 0.06424870390451129
    },
    {
      "iter": 0,
      "ops_idx": 25,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191210.364863829,
      "end_timestamp": 3191210.364886104,
      "duration_time": 2.2274907678365707e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.005166824703445929
    },
    {
      "iter": 0,
      "ops_idx": 26,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191210.396017842,
      "end_timestamp": 3191210.396067622,
      "duration_time": 4.978012293577194e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.00014182732594120154,
      "memory_efficiency": 0.0025221576909625234
    },
    {
      "iter": 0,
      "ops_idx": 27,
      "module_name": "model.decoder.layers.2.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.364788255,
      "end_timestamp": 3191210.42697335,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 28,
      "module_name": "model.decoder.layers.2.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.427247028,
      "end_timestamp": 3191210.427334984,
      "duration_time": 8.795596659183502e-05,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.004659364637139757,
      "memory_efficiency": 0.02058047234181347
    },
    {
      "iter": 0,
      "ops_idx": 29,
      "module_name": "model.decoder.layers.2.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.427507052,
      "end_timestamp": 3191210.427545628,
      "duration_time": 3.857584670186043e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003032963568822968
    },
    {
      "iter": 0,
      "ops_idx": 30,
      "module_name": "model.decoder.layers.2.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.427670779,
      "end_timestamp": 3191210.427750453,
      "duration_time": 7.967371493577957e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.020574861894855717,
      "memory_efficiency": 0.08871826732925793
    },
    {
      "iter": 0,
      "ops_idx": 31,
      "module_name": "model.decoder.layers.2.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.42797818,
      "end_timestamp": 3191210.428015795,
      "duration_time": 3.761518746614456e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.012206942409831278
    },
    {
      "iter": 0,
      "ops_idx": 32,
      "module_name": "model.decoder.layers.2.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.428295592,
      "end_timestamp": 3191210.428379286,
      "duration_time": 8.369423449039459e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.019586482765929402,
      "memory_efficiency": 0.08445640232958725
    },
    {
      "iter": 0,
      "ops_idx": 33,
      "module_name": "model.decoder.layers.3.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.428620224,
      "end_timestamp": 3191210.428654261,
      "duration_time": 3.403704613447189e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0034374057378835947
    },
    {
      "iter": 0,
      "ops_idx": 34,
      "module_name": "model.decoder.layers.3.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.428777247,
      "end_timestamp": 3191210.42885054,
      "duration_time": 7.329275831580162e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.01677460078378931,
      "memory_efficiency": 0.07252741646772737
    },
    {
      "iter": 0,
      "ops_idx": 35,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191210.429133814,
      "end_timestamp": 3191210.429155634,
      "duration_time": 2.1819956600666046e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0052745541783545185
    },
    {
      "iter": 0,
      "ops_idx": 36,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191210.459996857,
      "end_timestamp": 3191210.460046241,
      "duration_time": 4.9383845180273056e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.00014296541096044666,
      "memory_efficiency": 0.002542396596724931
    },
    {
      "iter": 0,
      "ops_idx": 37,
      "module_name": "model.decoder.layers.3.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.429064584,
      "end_timestamp": 3191210.490907407,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 38,
      "module_name": "model.decoder.layers.3.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.491193408,
      "end_timestamp": 3191210.491273143,
      "duration_time": 7.973471656441689e-05,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.005139780236534149,
      "memory_efficiency": 0.022702474100830438
    },
    {
      "iter": 0,
      "ops_idx": 39,
      "module_name": "model.decoder.layers.3.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.491434262,
      "end_timestamp": 3191210.491470292,
      "duration_time": 3.603007644414902e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0032472630987781873
    },
    {
      "iter": 0,
      "ops_idx": 40,
      "module_name": "model.decoder.layers.3.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.491601897,
      "end_timestamp": 3191210.491675019,
      "duration_time": 7.312186062335968e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.022418407675612144,
      "memory_efficiency": 0.09666758860522565
    },
    {
      "iter": 0,
      "ops_idx": 41,
      "module_name": "model.decoder.layers.3.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.491884958,
      "end_timestamp": 3191210.491911623,
      "duration_time": 2.6665162295103073e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.017219712449249094
    },
    {
      "iter": 0,
      "ops_idx": 42,
      "module_name": "model.decoder.layers.3.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.492199084,
      "end_timestamp": 3191210.492275708,
      "duration_time": 7.662409916520119e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.021393735121368246,
      "memory_efficiency": 0.09224922730312171
    },
    {
      "iter": 0,
      "ops_idx": 43,
      "module_name": "model.decoder.layers.4.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.49251427,
      "end_timestamp": 3191210.492549102,
      "duration_time": 3.4831929951906204e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0033589622465590497
    },
    {
      "iter": 0,
      "ops_idx": 44,
      "module_name": "model.decoder.layers.4.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.492680396,
      "end_timestamp": 3191210.492755763,
      "duration_time": 7.53672793507576e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.016312871735338387,
      "memory_efficiency": 0.07053106404039511
    },
    {
      "iter": 0,
      "ops_idx": 45,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191210.493021062,
      "end_timestamp": 3191210.493040362,
      "duration_time": 1.929979771375656e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0059633030856858565
    },
    {
      "iter": 0,
      "ops_idx": 46,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191210.523947178,
      "end_timestamp": 3191210.52399174,
      "duration_time": 4.4561922550201416e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.00015843530343761836,
      "memory_efficiency": 0.0028175023144047366
    },
    {
      "iter": 0,
      "ops_idx": 47,
      "module_name": "model.decoder.layers.4.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.492959747,
      "end_timestamp": 3191210.555172953,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 48,
      "module_name": "model.decoder.layers.4.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.555458802,
      "end_timestamp": 3191210.55554096,
      "duration_time": 8.215801790356636e-05,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.004988179252869394,
      "memory_efficiency": 0.022032850644783546
    },
    {
      "iter": 0,
      "ops_idx": 49,
      "module_name": "model.decoder.layers.4.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.555709222,
      "end_timestamp": 3191210.555745446,
      "duration_time": 3.6224257200956345e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003229856088813146
    },
    {
      "iter": 0,
      "ops_idx": 50,
      "module_name": "model.decoder.layers.4.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.555869165,
      "end_timestamp": 3191210.555950099,
      "duration_time": 8.093426004052162e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.020254409944972948,
      "memory_efficiency": 0.08733648688761182
    },
    {
      "iter": 0,
      "ops_idx": 51,
      "module_name": "model.decoder.layers.4.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.556188028,
      "end_timestamp": 3191210.556215877,
      "duration_time": 2.7849338948726654e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.016487516202075895
    },
    {
      "iter": 0,
      "ops_idx": 52,
      "module_name": "model.decoder.layers.4.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.556493828,
      "end_timestamp": 3191210.556571755,
      "duration_time": 7.792701944708824e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.02103603721898823,
      "memory_efficiency": 0.09070684328671189
    },
    {
      "iter": 0,
      "ops_idx": 53,
      "module_name": "model.decoder.layers.5.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.556819106,
      "end_timestamp": 3191210.556852978,
      "duration_time": 3.3872202038764954e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0034541343827998827
    },
    {
      "iter": 0,
      "ops_idx": 54,
      "module_name": "model.decoder.layers.5.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.556976896,
      "end_timestamp": 3191210.557049146,
      "duration_time": 7.225014269351959e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.017016668967777707,
      "memory_efficiency": 0.07357403332734763
    },
    {
      "iter": 0,
      "ops_idx": 55,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191210.557377667,
      "end_timestamp": 3191210.557396804,
      "duration_time": 1.9136816263198853e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.00601409041486607
    },
    {
      "iter": 0,
      "ops_idx": 56,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191210.588448601,
      "end_timestamp": 3191210.588489064,
      "duration_time": 4.0463171899318695e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.0001744841392704482,
      "memory_efficiency": 0.003102903554667476
    },
    {
      "iter": 0,
      "ops_idx": 57,
      "module_name": "model.decoder.layers.5.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.557316291,
      "end_timestamp": 3191210.61955026,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 58,
      "module_name": "model.decoder.layers.5.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.619831225,
      "end_timestamp": 3191210.619910219,
      "duration_time": 7.899431511759758e-05,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.005187954598420799,
      "memory_efficiency": 0.022915260864607167
    },
    {
      "iter": 0,
      "ops_idx": 59,
      "module_name": "model.decoder.layers.5.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.620080541,
      "end_timestamp": 3191210.620115558,
      "duration_time": 3.5017263144254684e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0033411845237950434
    },
    {
      "iter": 0,
      "ops_idx": 60,
      "module_name": "model.decoder.layers.5.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.620247633,
      "end_timestamp": 3191210.620321964,
      "duration_time": 7.433071732521057e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.022053812211735226,
      "memory_efficiency": 0.09509546248372033
    },
    {
      "iter": 0,
      "ops_idx": 61,
      "module_name": "model.decoder.layers.5.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.620530205,
      "end_timestamp": 3191210.620558389,
      "duration_time": 2.818414941430092e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.016291654588704685
    },
    {
      "iter": 0,
      "ops_idx": 62,
      "module_name": "model.decoder.layers.5.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.62084408,
      "end_timestamp": 3191210.620918369,
      "duration_time": 7.428880780935287e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.022066253716988376,
      "memory_efficiency": 0.09514910992955342
    },
    {
      "iter": 0,
      "ops_idx": 63,
      "module_name": "model.decoder.layers.6.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.62115661,
      "end_timestamp": 3191210.621191236,
      "duration_time": 3.4626107662916183e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0033789283745728625
    },
    {
      "iter": 0,
      "ops_idx": 64,
      "module_name": "model.decoder.layers.6.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.621320945,
      "end_timestamp": 3191210.621393979,
      "duration_time": 7.303385064005852e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.01683406735802012,
      "memory_efficiency": 0.0727845288157789
    },
    {
      "iter": 0,
      "ops_idx": 65,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191210.621661705,
      "end_timestamp": 3191210.621680144,
      "duration_time": 1.843925565481186e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.006241604618650841
    },
    {
      "iter": 0,
      "ops_idx": 66,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191210.652661789,
      "end_timestamp": 3191210.652704069,
      "duration_time": 4.2279716581106186e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.00016698744201515864,
      "memory_efficiency": 0.0029695875486455826
    },
    {
      "iter": 0,
      "ops_idx": 67,
      "module_name": "model.decoder.layers.6.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.621602804,
      "end_timestamp": 3191210.683788769,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 68,
      "module_name": "model.decoder.layers.6.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.684076363,
      "end_timestamp": 3191210.684158236,
      "duration_time": 8.187256753444672e-05,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.005005570641118791,
      "memory_efficiency": 0.02210966862593047
    },
    {
      "iter": 0,
      "ops_idx": 69,
      "module_name": "model.decoder.layers.6.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.684322771,
      "end_timestamp": 3191210.68435855,
      "duration_time": 3.577861934900284e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003270085313856671
    },
    {
      "iter": 0,
      "ops_idx": 70,
      "module_name": "model.decoder.layers.6.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.684482121,
      "end_timestamp": 3191210.684554365,
      "duration_time": 7.224408909678459e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.022690793142365582,
      "memory_efficiency": 0.09784210762652117
    },
    {
      "iter": 0,
      "ops_idx": 71,
      "module_name": "model.decoder.layers.6.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.684773193,
      "end_timestamp": 3191210.684798761,
      "duration_time": 2.556759864091873e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.01795891876992225
    },
    {
      "iter": 0,
      "ops_idx": 72,
      "module_name": "model.decoder.layers.6.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.685070221,
      "end_timestamp": 3191210.68514692,
      "duration_time": 7.669907063245773e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.02137282326808344,
      "memory_efficiency": 0.09215905593771705
    },
    {
      "iter": 0,
      "ops_idx": 73,
      "module_name": "model.decoder.layers.7.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.685389399,
      "end_timestamp": 3191210.685424285,
      "duration_time": 3.48859466612339e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0033537612958989744
    },
    {
      "iter": 0,
      "ops_idx": 74,
      "module_name": "model.decoder.layers.7.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.68555269,
      "end_timestamp": 3191210.685625981,
      "duration_time": 7.329089567065239e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.0167750271004347,
      "memory_efficiency": 0.07252925970950022
    },
    {
      "iter": 0,
      "ops_idx": 75,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191210.685894524,
      "end_timestamp": 3191210.685912332,
      "duration_time": 1.7807818949222565e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.006462921910186078
    },
    {
      "iter": 0,
      "ops_idx": 76,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191210.716916441,
      "end_timestamp": 3191210.716954849,
      "duration_time": 3.840820863842964e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.00018381960448789816,
      "memory_efficiency": 0.003268918920469874
    },
    {
      "iter": 0,
      "ops_idx": 77,
      "module_name": "model.decoder.layers.7.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.68583398,
      "end_timestamp": 3191210.747975912,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 78,
      "module_name": "model.decoder.layers.7.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.748262477,
      "end_timestamp": 3191210.748341335,
      "duration_time": 7.885787636041641e-05,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.005196930722435168,
      "memory_efficiency": 0.02295490851753862
    },
    {
      "iter": 0,
      "ops_idx": 79,
      "module_name": "model.decoder.layers.7.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.748499522,
      "end_timestamp": 3191210.748534303,
      "duration_time": 3.478117287158966e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0033638640685061784
    },
    {
      "iter": 0,
      "ops_idx": 80,
      "module_name": "model.decoder.layers.7.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.748667619,
      "end_timestamp": 3191210.748740373,
      "duration_time": 7.275398820638657e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.022531763850574274,
      "memory_efficiency": 0.09715637747219866
    },
    {
      "iter": 0,
      "ops_idx": 81,
      "module_name": "model.decoder.layers.7.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.748949032,
      "end_timestamp": 3191210.748974395,
      "duration_time": 2.5363173335790634e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.01810366632972903
    },
    {
      "iter": 0,
      "ops_idx": 82,
      "module_name": "model.decoder.layers.7.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.749255892,
      "end_timestamp": 3191210.749329672,
      "duration_time": 7.378030568361282e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.022218336807702653,
      "memory_efficiency": 0.09580488824618077
    },
    {
      "iter": 0,
      "ops_idx": 83,
      "module_name": "model.decoder.layers.8.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.749571287,
      "end_timestamp": 3191210.749605943,
      "duration_time": 3.465590998530388e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0033760226677890365
    },
    {
      "iter": 0,
      "ops_idx": 84,
      "module_name": "model.decoder.layers.8.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.749737454,
      "end_timestamp": 3191210.749810261,
      "duration_time": 7.280707359313965e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.016886501550120996,
      "memory_efficiency": 0.07301123564097645
    },
    {
      "iter": 0,
      "ops_idx": 85,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191210.750067652,
      "end_timestamp": 3191210.750085537,
      "duration_time": 1.788465306162834e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.00643515660398719
    },
    {
      "iter": 0,
      "ops_idx": 86,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191210.781098495,
      "end_timestamp": 3191210.781137855,
      "duration_time": 3.936002030968666e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.00017937444303775603,
      "memory_efficiency": 0.003189869286947952
    },
    {
      "iter": 0,
      "ops_idx": 87,
      "module_name": "model.decoder.layers.8.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.750013075,
      "end_timestamp": 3191210.812125838,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 88,
      "module_name": "model.decoder.layers.8.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.812407623,
      "end_timestamp": 3191210.812490708,
      "duration_time": 8.308514952659607e-05,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.004932517094793895,
      "memory_efficiency": 0.021786990190843694
    },
    {
      "iter": 0,
      "ops_idx": 89,
      "module_name": "model.decoder.layers.8.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.8126534,
      "end_timestamp": 3191210.812688874,
      "duration_time": 3.547407686710358e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0032981587687695387
    },
    {
      "iter": 0,
      "ops_idx": 90,
      "module_name": "model.decoder.layers.8.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.812811838,
      "end_timestamp": 3191210.812885036,
      "duration_time": 7.319822907447815e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.02239501832463499,
      "memory_efficiency": 0.09656673433445324
    },
    {
      "iter": 0,
      "ops_idx": 91,
      "module_name": "model.decoder.layers.8.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.813111914,
      "end_timestamp": 3191210.813137952,
      "duration_time": 2.603791654109955e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.01763453025934171
    },
    {
      "iter": 0,
      "ops_idx": 92,
      "module_name": "model.decoder.layers.8.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.813409579,
      "end_timestamp": 3191210.81348379,
      "duration_time": 7.421104237437248e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.022089376850201254,
      "memory_efficiency": 0.09524881627627661
    },
    {
      "iter": 0,
      "ops_idx": 93,
      "module_name": "model.decoder.layers.9.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.813730839,
      "end_timestamp": 3191210.813766027,
      "duration_time": 3.518769517540932e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0033250014557647516
    },
    {
      "iter": 0,
      "ops_idx": 94,
      "module_name": "model.decoder.layers.9.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.813892239,
      "end_timestamp": 3191210.81396656,
      "duration_time": 7.432140409946442e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.016542431833566313,
      "memory_efficiency": 0.07152360037930094
    },
    {
      "iter": 0,
      "ops_idx": 95,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191210.814231736,
      "end_timestamp": 3191210.814249497,
      "duration_time": 1.7760787159204483e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.006480036173391783
    },
    {
      "iter": 0,
      "ops_idx": 96,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191210.845116124,
      "end_timestamp": 3191210.845155446,
      "duration_time": 3.9321836084127426e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.00017954862804218618,
      "memory_efficiency": 0.0031929668708984248
    },
    {
      "iter": 0,
      "ops_idx": 97,
      "module_name": "model.decoder.layers.9.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.81417545,
      "end_timestamp": 3191210.876346082,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 98,
      "module_name": "model.decoder.layers.9.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.87662777,
      "end_timestamp": 3191210.876708066,
      "duration_time": 8.029630407691002e-05,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.005103832923255174,
      "memory_efficiency": 0.02254369436489747
    },
    {
      "iter": 0,
      "ops_idx": 99,
      "module_name": "model.decoder.layers.9.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.876872895,
      "end_timestamp": 3191210.876908059,
      "duration_time": 3.516441211104393e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0033272030060896973
    },
    {
      "iter": 0,
      "ops_idx": 100,
      "module_name": "model.decoder.layers.9.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.877035979,
      "end_timestamp": 3191210.877108765,
      "duration_time": 7.278565317392349e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.02252196154009458,
      "memory_efficiency": 0.09711411016532553
    },
    {
      "iter": 0,
      "ops_idx": 101,
      "module_name": "model.decoder.layers.9.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.877319975,
      "end_timestamp": 3191210.877345016,
      "duration_time": 2.5041401386260986e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.018336291170435715
    },
    {
      "iter": 0,
      "ops_idx": 102,
      "module_name": "model.decoder.layers.9.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.877635594,
      "end_timestamp": 3191210.877712355,
      "duration_time": 7.676100358366966e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.021355579069090126,
      "memory_efficiency": 0.09208469940186344
    },
    {
      "iter": 0,
      "ops_idx": 103,
      "module_name": "model.decoder.layers.10.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.877959347,
      "end_timestamp": 3191210.877993478,
      "duration_time": 3.413110971450806e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0034279324247552864
    },
    {
      "iter": 0,
      "ops_idx": 104,
      "module_name": "model.decoder.layers.10.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.878118149,
      "end_timestamp": 3191210.878198849,
      "duration_time": 8.070003241300583e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.015234897983661573,
      "memory_efficiency": 0.06587028836907796
    },
    {
      "iter": 0,
      "ops_idx": 105,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191210.878460286,
      "end_timestamp": 3191210.878478026,
      "duration_time": 1.7739832401275635e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.00648769056303381
    },
    {
      "iter": 0,
      "ops_idx": 106,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191210.909613512,
      "end_timestamp": 3191210.909652268,
      "duration_time": 3.875605762004852e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.00018216976015002556,
      "memory_efficiency": 0.0032395792459181485
    },
    {
      "iter": 0,
      "ops_idx": 107,
      "module_name": "model.decoder.layers.10.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.878404758,
      "end_timestamp": 3191210.940711229,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 108,
      "module_name": "model.decoder.layers.10.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.940986598,
      "end_timestamp": 3191210.941065089,
      "duration_time": 7.849093526601791e-05,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.0052212261068682935,
      "memory_efficiency": 0.023062221536866215
    },
    {
      "iter": 0,
      "ops_idx": 109,
      "module_name": "model.decoder.layers.10.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.941228987,
      "end_timestamp": 3191210.941264051,
      "duration_time": 3.506382927298546e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003336747300825555
    },
    {
      "iter": 0,
      "ops_idx": 110,
      "module_name": "model.decoder.layers.10.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.941389382,
      "end_timestamp": 3191210.941460472,
      "duration_time": 7.109018042683601e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.023059101434421928,
      "memory_efficiency": 0.09943024336620296
    },
    {
      "iter": 0,
      "ops_idx": 111,
      "module_name": "model.decoder.layers.10.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.941679851,
      "end_timestamp": 3191210.941705002,
      "duration_time": 2.5150831788778305e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.018256510599347374
    },
    {
      "iter": 0,
      "ops_idx": 112,
      "module_name": "model.decoder.layers.10.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.94197715,
      "end_timestamp": 3191210.942049886,
      "duration_time": 7.273629307746887e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.022537245329616026,
      "memory_efficiency": 0.09718001346671815
    },
    {
      "iter": 0,
      "ops_idx": 113,
      "module_name": "model.decoder.layers.11.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.942292387,
      "end_timestamp": 3191210.942326307,
      "duration_time": 3.391969949007034e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003449297589369642
    },
    {
      "iter": 0,
      "ops_idx": 114,
      "module_name": "model.decoder.layers.11.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191210.942455679,
      "end_timestamp": 3191210.942528758,
      "duration_time": 7.307901978492737e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184025088.0,
      "memory_byte": 3698688.0,
      "computes_efficiency": 0.01682366245070932,
      "memory_efficiency": 0.07273954169175936
    },
    {
      "iter": 0,
      "ops_idx": 115,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191210.942799325,
      "end_timestamp": 3191210.942816697,
      "duration_time": 1.737195998430252e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 80080.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.006625075314676889
    },
    {
      "iter": 0,
      "ops_idx": 116,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          26,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          26,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          26,
          12,
          64
        ],
        [
          12,
          26
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191210.9737198,
      "end_timestamp": 3191210.973757392,
      "duration_time": 3.7591904401779175e-05,
      "ops_type": "TensorCore",
      "computes_ops": 1056768.0,
      "memory_byte": 87360.0,
      "computes_efficiency": 0.0001878112277991072,
      "memory_efficiency": 0.0033399031498275154
    },
    {
      "iter": 0,
      "ops_idx": 117,
      "module_name": "model.decoder.layers.11.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          26,
          768
        ],
        [
          26,
          768
        ],
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191210.942739615,
      "end_timestamp": 3191211.004946779,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 0,
      "ops_idx": 118,
      "module_name": "model.decoder.layers.11.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.005235737,
      "end_timestamp": 3191211.005316768,
      "duration_time": 8.103065192699432e-05,
      "ops_type": "TensorCore",
      "computes_ops": 61341696.0,
      "memory_byte": 1259520.0,
      "computes_efficiency": 0.005057578960769981,
      "memory_efficiency": 0.02233939002948702
    },
    {
      "iter": 0,
      "ops_idx": 119,
      "module_name": "model.decoder.layers.11.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.005482044,
      "end_timestamp": 3191211.005516659,
      "duration_time": 3.46149317920208e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0033800193045653254
    },
    {
      "iter": 0,
      "ops_idx": 120,
      "module_name": "model.decoder.layers.11.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.005652043,
      "end_timestamp": 3191211.005725387,
      "duration_time": 7.334398105740547e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.022350514082003895,
      "memory_efficiency": 0.09637483320212929
    },
    {
      "iter": 0,
      "ops_idx": 121,
      "module_name": "model.decoder.layers.11.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.005934503,
      "end_timestamp": 3191211.005960724,
      "duration_time": 2.622092142701149e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 319488.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.017511452769208315
    },
    {
      "iter": 0,
      "ops_idx": 122,
      "module_name": "model.decoder.layers.11.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          26,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.006246119,
      "end_timestamp": 3191211.006320107,
      "duration_time": 7.398799061775208e-05,
      "ops_type": "TensorCore",
      "computes_ops": 245366784.0,
      "memory_byte": 4918272.0,
      "computes_efficiency": 0.02215596974274976,
      "memory_efficiency": 0.0955359630903616
    },
    {
      "iter": 0,
      "ops_idx": 123,
      "module_name": "model.decoder.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          26,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          26,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.006569817,
      "end_timestamp": 3191211.006609947,
      "duration_time": 4.0129758417606354e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 81408.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.002915520608564407
    },
    {
      "iter": 0,
      "ops_idx": 124,
      "module_name": "logits_processor",
      "operator_name": "LogitsProcessor",
      "input_shapes": [
        [],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "VocabParallelEmbedding",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          50272
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.006844333,
      "end_timestamp": 3191211.007155328,
      "duration_time": 0.0003109951503574848,
      "ops_type": "TensorCore",
      "computes_ops": 617742336.0,
      "memory_byte": 77626112.0,
      "computes_efficiency": 0.013270582151730447,
      "memory_efficiency": 0.3587317312124096
    },
    {
      "iter": 1,
      "ops_idx": 0,
      "module_name": "model.decoder.embed_tokens",
      "operator_name": "VocabParallelEmbedding",
      "input_shapes": [
        [
          4
        ]
      ],
      "input_dtypes": [
        "torch.int32"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.009045346,
      "end_timestamp": 3191211.009193279,
      "duration_time": 0.00014793267473578453,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12304.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.00011953574382800894
    },
    {
      "iter": 1,
      "ops_idx": 1,
      "module_name": "lm_head",
      "operator_name": "VocabParallelEmbedding",
      "input_shapes": [
        [
          4
        ]
      ],
      "input_dtypes": [
        "torch.int32"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.009045346,
      "end_timestamp": 3191211.009275554,
      "duration_time": 0.00023020803928375244,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12304.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 7.681418236316542e-05
    },
    {
      "iter": 1,
      "ops_idx": 2,
      "module_name": "model.decoder.embed_positions",
      "operator_name": "OPTLearnedPositionalEmbedding",
      "input_shapes": [
        [
          4
        ]
      ],
      "input_dtypes": [
        "torch.int64"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.009345603,
      "end_timestamp": 3191211.009403135,
      "duration_time": 5.753198638558388e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.00030776335977483364
    },
    {
      "iter": 1,
      "ops_idx": 3,
      "module_name": "model.decoder.layers.0.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.009507361,
      "end_timestamp": 3191211.00954461,
      "duration_time": 3.724917769432068e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005333749448161257
    },
    {
      "iter": 1,
      "ops_idx": 4,
      "module_name": "model.decoder.layers.0.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.009634715,
      "end_timestamp": 3191211.00984177,
      "duration_time": 0.00020705489441752434,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0009135123057389926,
      "memory_efficiency": 0.02473484967198628
    },
    {
      "iter": 1,
      "ops_idx": 5,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191211.010039365,
      "end_timestamp": 3191211.010057929,
      "duration_time": 1.8564052879810333e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0009537915852310471
    },
    {
      "iter": 1,
      "ops_idx": 6,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191211.041275315,
      "end_timestamp": 3191211.045697388,
      "duration_time": 0.004422072786837816,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 2.7847281212254456e-07,
      "memory_efficiency": 1.9781088217347658e-05
    },
    {
      "iter": 1,
      "ops_idx": 7,
      "module_name": "model.decoder.layers.0.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.009969724,
      "end_timestamp": 3191211.076861128,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 8,
      "module_name": "model.decoder.layers.0.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.077059768,
      "end_timestamp": 3191211.077690778,
      "duration_time": 0.0006310096941888332,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 9.991774334362442e-05,
      "memory_efficiency": 0.002714766498725143
    },
    {
      "iter": 1,
      "ops_idx": 9,
      "module_name": "model.decoder.layers.0.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.077834357,
      "end_timestamp": 3191211.077876407,
      "duration_time": 4.205014556646347e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0004724782240230729
    },
    {
      "iter": 1,
      "ops_idx": 10,
      "module_name": "model.decoder.layers.0.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.077961523,
      "end_timestamp": 3191211.078053113,
      "duration_time": 9.158998727798462e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.002753535251836586,
      "memory_efficiency": 0.07452436390350985
    },
    {
      "iter": 1,
      "ops_idx": 11,
      "module_name": "model.decoder.layers.0.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.078162891,
      "end_timestamp": 3191211.078189488,
      "duration_time": 2.6597175747156143e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0026559582664499753
    },
    {
      "iter": 1,
      "ops_idx": 12,
      "module_name": "model.decoder.layers.0.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.078286907,
      "end_timestamp": 3191211.078423901,
      "duration_time": 0.00013699382543563843,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0018409315739830942,
      "memory_efficiency": 0.04982476779604321
    },
    {
      "iter": 1,
      "ops_idx": 13,
      "module_name": "model.decoder.layers.1.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.07857676,
      "end_timestamp": 3191211.078613646,
      "duration_time": 3.688596189022064e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005386270841000294
    },
    {
      "iter": 1,
      "ops_idx": 14,
      "module_name": "model.decoder.layers.1.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.078703556,
      "end_timestamp": 3191211.078772037,
      "duration_time": 6.848061457276344e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.002762054563819951,
      "memory_efficiency": 0.07478717472409194
    },
    {
      "iter": 1,
      "ops_idx": 15,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191211.078945663,
      "end_timestamp": 3191211.078963987,
      "duration_time": 1.8324237316846848e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0009662741820238602
    },
    {
      "iter": 1,
      "ops_idx": 16,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191211.109952491,
      "end_timestamp": 3191211.110000207,
      "duration_time": 4.771631211042404e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 2.5807255210997086e-05,
      "memory_efficiency": 0.0018331972449493205
    },
    {
      "iter": 1,
      "ops_idx": 17,
      "module_name": "model.decoder.layers.1.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.078883202,
      "end_timestamp": 3191211.141106264,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 18,
      "module_name": "model.decoder.layers.1.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.141300938,
      "end_timestamp": 3191211.141385041,
      "duration_time": 8.410308510065079e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0007496641127474039,
      "memory_efficiency": 0.020368384537910213
    },
    {
      "iter": 1,
      "ops_idx": 19,
      "module_name": "model.decoder.layers.1.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.141501947,
      "end_timestamp": 3191211.141539376,
      "duration_time": 3.7429388612508774e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005308069095874735
    },
    {
      "iter": 1,
      "ops_idx": 20,
      "module_name": "model.decoder.layers.1.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.141614639,
      "end_timestamp": 3191211.14167746,
      "duration_time": 6.282096728682518e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004014523646758392,
      "memory_efficiency": 0.10865298381443175
    },
    {
      "iter": 1,
      "ops_idx": 21,
      "module_name": "model.decoder.layers.1.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.141783108,
      "end_timestamp": 3191211.141808375,
      "duration_time": 2.5266781449317932e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.002795804797361283
    },
    {
      "iter": 1,
      "ops_idx": 22,
      "module_name": "model.decoder.layers.1.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.141913215,
      "end_timestamp": 3191211.141981123,
      "duration_time": 6.790785118937492e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0037138011918812493,
      "memory_efficiency": 0.10051393796554604
    },
    {
      "iter": 1,
      "ops_idx": 23,
      "module_name": "model.decoder.layers.2.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.142102249,
      "end_timestamp": 3191211.142136357,
      "duration_time": 3.410782665014267e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005824990932710528
    },
    {
      "iter": 1,
      "ops_idx": 24,
      "module_name": "model.decoder.layers.2.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.14222117,
      "end_timestamp": 3191211.142282742,
      "duration_time": 6.157206371426582e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0030719645014931052,
      "memory_efficiency": 0.08317849651805395
    },
    {
      "iter": 1,
      "ops_idx": 25,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191211.143133709,
      "end_timestamp": 3191211.143153057,
      "duration_time": 1.934776082634926e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0009151569312575735
    },
    {
      "iter": 1,
      "ops_idx": 26,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191211.174268167,
      "end_timestamp": 3191211.174310475,
      "duration_time": 4.230812191963196e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 2.910616185470273e-05,
      "memory_efficiency": 0.0020675323774979842
    },
    {
      "iter": 1,
      "ops_idx": 27,
      "module_name": "model.decoder.layers.2.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.14306904,
      "end_timestamp": 3191211.20528053,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 28,
      "module_name": "model.decoder.layers.2.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.205468551,
      "end_timestamp": 3191211.20554177,
      "duration_time": 7.3219183832407e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008611003479035381,
      "memory_efficiency": 0.023396108621965336
    },
    {
      "iter": 1,
      "ops_idx": 29,
      "module_name": "model.decoder.layers.2.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.205657953,
      "end_timestamp": 3191211.20569431,
      "duration_time": 3.635697066783905e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005464640681609141
    },
    {
      "iter": 1,
      "ops_idx": 30,
      "module_name": "model.decoder.layers.2.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.205769797,
      "end_timestamp": 3191211.205830732,
      "duration_time": 6.0935039073228836e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004138772412734775,
      "memory_efficiency": 0.1120157736112974
    },
    {
      "iter": 1,
      "ops_idx": 31,
      "module_name": "model.decoder.layers.2.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.205939309,
      "end_timestamp": 3191211.205963949,
      "duration_time": 2.4640001356601715e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.002866923088498757
    },
    {
      "iter": 1,
      "ops_idx": 32,
      "module_name": "model.decoder.layers.2.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.206066377,
      "end_timestamp": 3191211.206133488,
      "duration_time": 6.711110472679138e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.00375789162928972,
      "memory_efficiency": 0.10170724457017447
    },
    {
      "iter": 1,
      "ops_idx": 33,
      "module_name": "model.decoder.layers.3.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.206258057,
      "end_timestamp": 3191211.206292637,
      "duration_time": 3.458000719547272e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005745452273866352
    },
    {
      "iter": 1,
      "ops_idx": 34,
      "module_name": "model.decoder.layers.3.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.206372909,
      "end_timestamp": 3191211.206437993,
      "duration_time": 6.508408114314079e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0029061975016271783,
      "memory_efficiency": 0.07869008208017403
    },
    {
      "iter": 1,
      "ops_idx": 35,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191211.206605671,
      "end_timestamp": 3191211.206622755,
      "duration_time": 1.7084181308746338e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.001036411233559227
    },
    {
      "iter": 1,
      "ops_idx": 36,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191211.237601839,
      "end_timestamp": 3191211.237643087,
      "duration_time": 4.1247811168432236e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 2.9854360982522624e-05,
      "memory_efficiency": 0.0021206800899756925
    },
    {
      "iter": 1,
      "ops_idx": 37,
      "module_name": "model.decoder.layers.3.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.206545119,
      "end_timestamp": 3191211.268748119,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 38,
      "module_name": "model.decoder.layers.3.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.268930746,
      "end_timestamp": 3191211.269005468,
      "duration_time": 7.472233846783638e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008437779914829315,
      "memory_efficiency": 0.022925459953210752
    },
    {
      "iter": 1,
      "ops_idx": 39,
      "module_name": "model.decoder.layers.3.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.269120408,
      "end_timestamp": 3191211.269155592,
      "duration_time": 3.5183969885110855e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005646826711718508
    },
    {
      "iter": 1,
      "ops_idx": 40,
      "module_name": "model.decoder.layers.3.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.269235733,
      "end_timestamp": 3191211.269297662,
      "duration_time": 6.192922592163086e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0040723302274816115,
      "memory_efficiency": 0.11021751750070338
    },
    {
      "iter": 1,
      "ops_idx": 41,
      "module_name": "model.decoder.layers.3.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.269396501,
      "end_timestamp": 3191211.269422224,
      "duration_time": 2.572266384959221e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0027462547892761133
    },
    {
      "iter": 1,
      "ops_idx": 42,
      "module_name": "model.decoder.layers.3.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.269519666,
      "end_timestamp": 3191211.269585262,
      "duration_time": 6.5595842897892e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0038446988032118075,
      "memory_efficiency": 0.10405667859848043
    },
    {
      "iter": 1,
      "ops_idx": 43,
      "module_name": "model.decoder.layers.4.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.269717812,
      "end_timestamp": 3191211.269751459,
      "duration_time": 3.364682197570801e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.000590480078965505
    },
    {
      "iter": 1,
      "ops_idx": 44,
      "module_name": "model.decoder.layers.4.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.269846791,
      "end_timestamp": 3191211.269911102,
      "duration_time": 6.431108340620995e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0029411290246687412,
      "memory_efficiency": 0.07963591057730371
    },
    {
      "iter": 1,
      "ops_idx": 45,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191211.270080727,
      "end_timestamp": 3191211.270098325,
      "duration_time": 1.7597805708646774e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010061616611579721
    },
    {
      "iter": 1,
      "ops_idx": 46,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191211.301151922,
      "end_timestamp": 3191211.3011917,
      "duration_time": 3.977818414568901e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 3.0957346867598557e-05,
      "memory_efficiency": 0.0021990297892834115
    },
    {
      "iter": 1,
      "ops_idx": 47,
      "module_name": "model.decoder.layers.4.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.270019856,
      "end_timestamp": 3191211.332021797,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 48,
      "module_name": "model.decoder.layers.4.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.332212029,
      "end_timestamp": 3191211.332284412,
      "duration_time": 7.23828561604023e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008710496934741066,
      "memory_efficiency": 0.02366643248172595
    },
    {
      "iter": 1,
      "ops_idx": 49,
      "module_name": "model.decoder.layers.4.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.3324002,
      "end_timestamp": 3191211.332434196,
      "duration_time": 3.399606794118881e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.000584414001393468
    },
    {
      "iter": 1,
      "ops_idx": 50,
      "module_name": "model.decoder.layers.4.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.332515181,
      "end_timestamp": 3191211.332575875,
      "duration_time": 6.069382652640343e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004155220936275669,
      "memory_efficiency": 0.11246095249659384
    },
    {
      "iter": 1,
      "ops_idx": 51,
      "module_name": "model.decoder.layers.4.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.332673492,
      "end_timestamp": 3191211.33269734,
      "duration_time": 2.384791150689125e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0029621457111441087
    },
    {
      "iter": 1,
      "ops_idx": 52,
      "module_name": "model.decoder.layers.4.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.332793192,
      "end_timestamp": 3191211.332859829,
      "duration_time": 6.66370615363121e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.003784624544822815,
      "memory_efficiency": 0.10243077027192872
    },
    {
      "iter": 1,
      "ops_idx": 53,
      "module_name": "model.decoder.layers.5.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.332983342,
      "end_timestamp": 3191211.333019997,
      "duration_time": 3.6654993891716003e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005420210450954257
    },
    {
      "iter": 1,
      "ops_idx": 54,
      "module_name": "model.decoder.layers.5.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.333098418,
      "end_timestamp": 3191211.333160496,
      "duration_time": 6.207777187228203e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0030469391588835567,
      "memory_efficiency": 0.08250089416552035
    },
    {
      "iter": 1,
      "ops_idx": 55,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191211.333328229,
      "end_timestamp": 3191211.33334453,
      "duration_time": 1.630093902349472e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010862096593961298
    },
    {
      "iter": 1,
      "ops_idx": 56,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191211.36455454,
      "end_timestamp": 3191211.364594812,
      "duration_time": 4.027225077152252e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 3.057755702177133e-05,
      "memory_efficiency": 0.0021720517285273213
    },
    {
      "iter": 1,
      "ops_idx": 57,
      "module_name": "model.decoder.layers.5.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.333271885,
      "end_timestamp": 3191211.395708645,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 58,
      "module_name": "model.decoder.layers.5.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.395893993,
      "end_timestamp": 3191211.395970427,
      "duration_time": 7.643410935997963e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008248812630805748,
      "memory_efficiency": 0.022412035575462338
    },
    {
      "iter": 1,
      "ops_idx": 59,
      "module_name": "model.decoder.layers.5.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.396098223,
      "end_timestamp": 3191211.396133695,
      "duration_time": 3.547174856066704e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005601014582964428
    },
    {
      "iter": 1,
      "ops_idx": 60,
      "module_name": "model.decoder.layers.5.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.396208746,
      "end_timestamp": 3191211.396270534,
      "duration_time": 6.178813055157661e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004081629536836018,
      "memory_efficiency": 0.11046920307978464
    },
    {
      "iter": 1,
      "ops_idx": 61,
      "module_name": "model.decoder.layers.5.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.396376249,
      "end_timestamp": 3191211.396400162,
      "duration_time": 2.3913104087114334e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.002954070225786677
    },
    {
      "iter": 1,
      "ops_idx": 62,
      "module_name": "model.decoder.layers.5.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.396507083,
      "end_timestamp": 3191211.396574188,
      "duration_time": 6.710505113005638e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.003758230631497668,
      "memory_efficiency": 0.10171641965659922
    },
    {
      "iter": 1,
      "ops_idx": 63,
      "module_name": "model.decoder.layers.6.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.3967001,
      "end_timestamp": 3191211.396734056,
      "duration_time": 3.395602107048035e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005851032444560002
    },
    {
      "iter": 1,
      "ops_idx": 64,
      "module_name": "model.decoder.layers.6.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.396815694,
      "end_timestamp": 3191211.396875625,
      "duration_time": 5.993107333779335e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.003156078866597197,
      "memory_efficiency": 0.08545603143798171
    },
    {
      "iter": 1,
      "ops_idx": 65,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191211.397042904,
      "end_timestamp": 3191211.397059839,
      "duration_time": 1.693516969680786e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010455305580956038
    },
    {
      "iter": 1,
      "ops_idx": 66,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191211.428047217,
      "end_timestamp": 3191211.428087094,
      "duration_time": 3.987690433859825e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 3.0880708138855276e-05,
      "memory_efficiency": 0.002193585819932935
    },
    {
      "iter": 1,
      "ops_idx": 67,
      "module_name": "model.decoder.layers.6.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.396985682,
      "end_timestamp": 3191211.459224201,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 68,
      "module_name": "model.decoder.layers.6.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.459412018,
      "end_timestamp": 3191211.459483362,
      "duration_time": 7.134396582841873e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008837336688421683,
      "memory_efficiency": 0.02401105627173137
    },
    {
      "iter": 1,
      "ops_idx": 69,
      "module_name": "model.decoder.layers.6.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.459598969,
      "end_timestamp": 3191211.459632835,
      "duration_time": 3.3865682780742645e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005866640346744153
    },
    {
      "iter": 1,
      "ops_idx": 70,
      "module_name": "model.decoder.layers.6.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.459705767,
      "end_timestamp": 3191211.459764402,
      "duration_time": 5.8634672313928604e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.00430114552930291,
      "memory_efficiency": 0.11641039801975543
    },
    {
      "iter": 1,
      "ops_idx": 71,
      "module_name": "model.decoder.layers.6.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.459862747,
      "end_timestamp": 3191211.459886112,
      "duration_time": 2.3364555090665817e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003023425377275999
    },
    {
      "iter": 1,
      "ops_idx": 72,
      "module_name": "model.decoder.layers.6.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.459992795,
      "end_timestamp": 3191211.460074952,
      "duration_time": 8.215708658099174e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0030696835681554516,
      "memory_efficiency": 0.083080910313117
    },
    {
      "iter": 1,
      "ops_idx": 73,
      "module_name": "model.decoder.layers.7.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.460220758,
      "end_timestamp": 3191211.460254856,
      "duration_time": 3.409804776310921e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005826661466129264
    },
    {
      "iter": 1,
      "ops_idx": 74,
      "module_name": "model.decoder.layers.7.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.46033454,
      "end_timestamp": 3191211.460394896,
      "duration_time": 6.0356222093105316e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0031338474718003136,
      "memory_efficiency": 0.08485407982239329
    },
    {
      "iter": 1,
      "ops_idx": 75,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191211.460560672,
      "end_timestamp": 3191211.460579126,
      "duration_time": 1.8454156816005707e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0009594714947469322
    },
    {
      "iter": 1,
      "ops_idx": 76,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191211.491569334,
      "end_timestamp": 3191211.491608973,
      "duration_time": 3.9638951420783997e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 3.106608525763441e-05,
      "memory_efficiency": 0.002206753931793112
    },
    {
      "iter": 1,
      "ops_idx": 77,
      "module_name": "model.decoder.layers.7.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.460505059,
      "end_timestamp": 3191211.522507029,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 78,
      "module_name": "model.decoder.layers.7.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.522685699,
      "end_timestamp": 3191211.522755252,
      "duration_time": 6.955303251743317e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0009064890830675974,
      "memory_efficiency": 0.0246293211978252
    },
    {
      "iter": 1,
      "ops_idx": 79,
      "module_name": "model.decoder.layers.7.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.522866665,
      "end_timestamp": 3191211.522900745,
      "duration_time": 3.4079886972904205e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005829766428788502
    },
    {
      "iter": 1,
      "ops_idx": 80,
      "module_name": "model.decoder.layers.7.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.522980028,
      "end_timestamp": 3191211.523043208,
      "duration_time": 6.317999213933945e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0039917108272028955,
      "memory_efficiency": 0.10803555541394731
    },
    {
      "iter": 1,
      "ops_idx": 81,
      "module_name": "model.decoder.layers.7.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.52314343,
      "end_timestamp": 3191211.523166526,
      "duration_time": 2.309633418917656e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003058536831484974
    },
    {
      "iter": 1,
      "ops_idx": 82,
      "module_name": "model.decoder.layers.7.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.523262237,
      "end_timestamp": 3191211.523325844,
      "duration_time": 6.360700353980064e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.00396491336881463,
      "memory_efficiency": 0.10731028286140447
    },
    {
      "iter": 1,
      "ops_idx": 83,
      "module_name": "model.decoder.layers.8.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.523444785,
      "end_timestamp": 3191211.523478379,
      "duration_time": 3.359420225024223e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005914049677131743
    },
    {
      "iter": 1,
      "ops_idx": 84,
      "module_name": "model.decoder.layers.8.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.523561896,
      "end_timestamp": 3191211.523622268,
      "duration_time": 6.037205457687378e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.003133025624845164,
      "memory_efficiency": 0.08483182696300509
    },
    {
      "iter": 1,
      "ops_idx": 85,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191211.523796943,
      "end_timestamp": 3191211.523813597,
      "duration_time": 1.6653910279273987e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010631879917464748
    },
    {
      "iter": 1,
      "ops_idx": 86,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191211.554868222,
      "end_timestamp": 3191211.554908247,
      "duration_time": 4.002498462796211e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 3.0766458895802024e-05,
      "memory_efficiency": 0.0021854702184909993
    },
    {
      "iter": 1,
      "ops_idx": 87,
      "module_name": "model.decoder.layers.8.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.52374164,
      "end_timestamp": 3191211.585950313,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 88,
      "module_name": "model.decoder.layers.8.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.586142826,
      "end_timestamp": 3191211.586217954,
      "duration_time": 7.512792944908142e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008392227116285802,
      "memory_efficiency": 0.022801692935190927
    },
    {
      "iter": 1,
      "ops_idx": 89,
      "module_name": "model.decoder.layers.8.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.586334196,
      "end_timestamp": 3191211.586374507,
      "duration_time": 4.0310900658369064e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0004928636615076361
    },
    {
      "iter": 1,
      "ops_idx": 90,
      "module_name": "model.decoder.layers.8.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.586453112,
      "end_timestamp": 3191211.586514993,
      "duration_time": 6.188126280903816e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004075486621264623,
      "memory_efficiency": 0.11030294522085006
    },
    {
      "iter": 1,
      "ops_idx": 91,
      "module_name": "model.decoder.layers.8.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.586623178,
      "end_timestamp": 3191211.586650749,
      "duration_time": 2.7571339160203934e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.002562116710378882
    },
    {
      "iter": 1,
      "ops_idx": 92,
      "module_name": "model.decoder.layers.8.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.58674749,
      "end_timestamp": 3191211.586812766,
      "duration_time": 6.527593359351158e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0038635411981340602,
      "memory_efficiency": 0.10456664755386716
    },
    {
      "iter": 1,
      "ops_idx": 93,
      "module_name": "model.decoder.layers.9.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.586936262,
      "end_timestamp": 3191211.586970073,
      "duration_time": 3.381120041012764e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.000587609367788174
    },
    {
      "iter": 1,
      "ops_idx": 94,
      "module_name": "model.decoder.layers.9.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.587053251,
      "end_timestamp": 3191211.587113634,
      "duration_time": 6.0383230447769165e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0031324457570634048,
      "memory_efficiency": 0.08481612608812761
    },
    {
      "iter": 1,
      "ops_idx": 95,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191211.587281154,
      "end_timestamp": 3191211.587298381,
      "duration_time": 1.7227139323949814e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010278106591923482
    },
    {
      "iter": 1,
      "ops_idx": 96,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191211.617253459,
      "end_timestamp": 3191211.617293666,
      "duration_time": 4.020705819129944e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 3.062713612377086e-05,
      "memory_efficiency": 0.0021755735394463644
    },
    {
      "iter": 1,
      "ops_idx": 97,
      "module_name": "model.decoder.layers.9.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.587221874,
      "end_timestamp": 3191211.647349835,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 98,
      "module_name": "model.decoder.layers.9.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.647537065,
      "end_timestamp": 3191211.647608081,
      "duration_time": 7.101567462086678e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008878189921858865,
      "memory_efficiency": 0.02412205456471567
    },
    {
      "iter": 1,
      "ops_idx": 99,
      "module_name": "model.decoder.layers.9.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.647722423,
      "end_timestamp": 3191211.647757422,
      "duration_time": 3.499910235404968e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005676653617047835
    },
    {
      "iter": 1,
      "ops_idx": 100,
      "module_name": "model.decoder.layers.9.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.64783403,
      "end_timestamp": 3191211.6478944,
      "duration_time": 6.037019193172455e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004177496387131178,
      "memory_efficiency": 0.1130638370264227
    },
    {
      "iter": 1,
      "ops_idx": 101,
      "module_name": "model.decoder.layers.9.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.647992387,
      "end_timestamp": 3191211.648023203,
      "duration_time": 3.081606701016426e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0022923427823084036
    },
    {
      "iter": 1,
      "ops_idx": 102,
      "module_name": "model.decoder.layers.9.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.648125707,
      "end_timestamp": 3191211.648195586,
      "duration_time": 6.987899541854858e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.003609042419322652,
      "memory_efficiency": 0.09767864436142942
    },
    {
      "iter": 1,
      "ops_idx": 103,
      "module_name": "model.decoder.layers.10.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.648321715,
      "end_timestamp": 3191211.648358328,
      "duration_time": 3.6612618714571e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005426483762891132
    },
    {
      "iter": 1,
      "ops_idx": 104,
      "module_name": "model.decoder.layers.10.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.648437693,
      "end_timestamp": 3191211.648496662,
      "duration_time": 5.896901711821556e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.003207569046550526,
      "memory_efficiency": 0.08685021283294257
    },
    {
      "iter": 1,
      "ops_idx": 105,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191211.648662948,
      "end_timestamp": 3191211.648679959,
      "duration_time": 1.7011072486639023e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.001040865438581504
    },
    {
      "iter": 1,
      "ops_idx": 106,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191211.678675164,
      "end_timestamp": 3191211.678714692,
      "duration_time": 3.9528124034404755e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 3.1153187115317853e-05,
      "memory_efficiency": 0.002212941140941461
    },
    {
      "iter": 1,
      "ops_idx": 107,
      "module_name": "model.decoder.layers.10.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.648605939,
      "end_timestamp": 3191211.70869747,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 108,
      "module_name": "model.decoder.layers.10.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.708884026,
      "end_timestamp": 3191211.708954462,
      "duration_time": 7.043592631816864e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008951265066991182,
      "memory_efficiency": 0.02432059983731299
    },
    {
      "iter": 1,
      "ops_idx": 109,
      "module_name": "model.decoder.layers.10.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.70906822,
      "end_timestamp": 3191211.709103589,
      "duration_time": 3.536883741617203e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.000561731160777991
    },
    {
      "iter": 1,
      "ops_idx": 110,
      "module_name": "model.decoder.layers.10.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.709180659,
      "end_timestamp": 3191211.709242207,
      "duration_time": 6.154784932732582e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0040975641137996,
      "memory_efficiency": 0.11090047201359994
    },
    {
      "iter": 1,
      "ops_idx": 111,
      "module_name": "model.decoder.layers.10.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.709336843,
      "end_timestamp": 3191211.709359427,
      "duration_time": 2.2584106773138046e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003127907138390961
    },
    {
      "iter": 1,
      "ops_idx": 112,
      "module_name": "model.decoder.layers.10.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.709455647,
      "end_timestamp": 3191211.709518359,
      "duration_time": 6.271200254559517e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0040214990503904605,
      "memory_efficiency": 0.10884177294226419
    },
    {
      "iter": 1,
      "ops_idx": 113,
      "module_name": "model.decoder.layers.11.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.709650393,
      "end_timestamp": 3191211.709684322,
      "duration_time": 3.39290127158165e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005855690014785695
    },
    {
      "iter": 1,
      "ops_idx": 114,
      "module_name": "model.decoder.layers.11.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.709766681,
      "end_timestamp": 3191211.709825887,
      "duration_time": 5.92060387134552e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.003194728073758304,
      "memory_efficiency": 0.08650252235339209
    },
    {
      "iter": 1,
      "ops_idx": 115,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191211.709985635,
      "end_timestamp": 3191211.710001927,
      "duration_time": 1.6292091459035873e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010867995351650876
    },
    {
      "iter": 1,
      "ops_idx": 116,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191211.739979955,
      "end_timestamp": 3191211.740030727,
      "duration_time": 5.077198147773743e-05,
      "ops_type": "TensorCore",
      "computes_ops": 184320.0,
      "memory_byte": 60864.0,
      "computes_efficiency": 2.4254067076370895e-05,
      "memory_efficiency": 0.0017228677974352197
    },
    {
      "iter": 1,
      "ops_idx": 117,
      "module_name": "model.decoder.layers.11.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.709931262,
      "end_timestamp": 3191211.769934126,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 1,
      "ops_idx": 118,
      "module_name": "model.decoder.layers.11.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.77011672,
      "end_timestamp": 3191211.770185519,
      "duration_time": 6.879912689328194e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0009164224535741217,
      "memory_efficiency": 0.024899211014869967
    },
    {
      "iter": 1,
      "ops_idx": 119,
      "module_name": "model.decoder.layers.11.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.770358591,
      "end_timestamp": 3191211.77039298,
      "duration_time": 3.4389086067676544e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005777349842346856
    },
    {
      "iter": 1,
      "ops_idx": 120,
      "module_name": "model.decoder.layers.11.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.770474402,
      "end_timestamp": 3191211.770537018,
      "duration_time": 6.261607632040977e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004027659883936092,
      "memory_efficiency": 0.10900851575073099
    },
    {
      "iter": 1,
      "ops_idx": 121,
      "module_name": "model.decoder.layers.11.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.770653933,
      "end_timestamp": 3191211.770682337,
      "duration_time": 2.840440720319748e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0024869728237782098
    },
    {
      "iter": 1,
      "ops_idx": 122,
      "module_name": "model.decoder.layers.11.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.770785971,
      "end_timestamp": 3191211.770854943,
      "duration_time": 6.897188723087311e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0036565080181292665,
      "memory_efficiency": 0.09896329962633034
    },
    {
      "iter": 1,
      "ops_idx": 123,
      "module_name": "model.decoder.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.770984673,
      "end_timestamp": 3191211.771022561,
      "duration_time": 3.78880649805069e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005243809127591014
    },
    {
      "iter": 1,
      "ops_idx": 124,
      "module_name": "logits_processor",
      "operator_name": "LogitsProcessor",
      "input_shapes": [
        [],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "VocabParallelEmbedding",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          50272
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.771209703,
      "end_timestamp": 3191211.771298925,
      "duration_time": 8.922209963202477e-05,
      "ops_type": "TensorCore",
      "computes_ops": 617742336.0,
      "memory_byte": 77626112.0,
      "computes_efficiency": 0.04625632784511851,
      "memory_efficiency": 1.2504057755480145
    },
    {
      "iter": 2,
      "ops_idx": 0,
      "module_name": "model.decoder.embed_tokens",
      "operator_name": "VocabParallelEmbedding",
      "input_shapes": [
        [
          4
        ]
      ],
      "input_dtypes": [
        "torch.int32"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.773108456,
      "end_timestamp": 3191211.773183136,
      "duration_time": 7.467996329069138e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12304.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.00023678697112071385
    },
    {
      "iter": 2,
      "ops_idx": 1,
      "module_name": "lm_head",
      "operator_name": "VocabParallelEmbedding",
      "input_shapes": [
        [
          4
        ]
      ],
      "input_dtypes": [
        "torch.int32"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.773108456,
      "end_timestamp": 3191211.773270078,
      "duration_time": 0.00016162218526005745,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12304.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.00010941098391013442
    },
    {
      "iter": 2,
      "ops_idx": 2,
      "module_name": "model.decoder.embed_positions",
      "operator_name": "OPTLearnedPositionalEmbedding",
      "input_shapes": [
        [
          4
        ]
      ],
      "input_dtypes": [
        "torch.int64"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.773346371,
      "end_timestamp": 3191211.773401602,
      "duration_time": 5.523115396499634e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0003205842383045066
    },
    {
      "iter": 2,
      "ops_idx": 3,
      "module_name": "model.decoder.layers.0.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.773501219,
      "end_timestamp": 3191211.773537732,
      "duration_time": 3.651296719908714e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005441293770737719
    },
    {
      "iter": 2,
      "ops_idx": 4,
      "module_name": "model.decoder.layers.0.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.773622205,
      "end_timestamp": 3191211.773697986,
      "duration_time": 7.578078657388687e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0024959782362443056,
      "memory_efficiency": 0.06758272009057309
    },
    {
      "iter": 2,
      "ops_idx": 5,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191211.773878699,
      "end_timestamp": 3191211.773899394,
      "duration_time": 2.0694918930530548e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.000855583802187591
    },
    {
      "iter": 2,
      "ops_idx": 6,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191211.804021874,
      "end_timestamp": 3191211.804063805,
      "duration_time": 4.193093627691269e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.3283714623640374e-05,
      "memory_efficiency": 0.002336203108524577
    },
    {
      "iter": 2,
      "ops_idx": 7,
      "module_name": "model.decoder.layers.0.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.773816481,
      "end_timestamp": 3191211.834044583,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 8,
      "module_name": "model.decoder.layers.0.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.834235074,
      "end_timestamp": 3191211.834311305,
      "duration_time": 7.623108103871346e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008270781918897323,
      "memory_efficiency": 0.02247172616225505
    },
    {
      "iter": 2,
      "ops_idx": 9,
      "module_name": "model.decoder.layers.0.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.834434739,
      "end_timestamp": 3191211.834470704,
      "duration_time": 3.596534952521324e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005524144310964139
    },
    {
      "iter": 2,
      "ops_idx": 10,
      "module_name": "model.decoder.layers.0.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.834549843,
      "end_timestamp": 3191211.834612486,
      "duration_time": 6.264308467507362e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004025923371962345,
      "memory_efficiency": 0.1089615170968485
    },
    {
      "iter": 2,
      "ops_idx": 11,
      "module_name": "model.decoder.layers.0.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.834708703,
      "end_timestamp": 3191211.834732383,
      "duration_time": 2.3679807782173157e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0029831740797770633
    },
    {
      "iter": 2,
      "ops_idx": 12,
      "module_name": "model.decoder.layers.0.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.834830438,
      "end_timestamp": 3191211.834895517,
      "duration_time": 6.507942453026772e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0038752072641315602,
      "memory_efficiency": 0.10488238934331406
    },
    {
      "iter": 2,
      "ops_idx": 13,
      "module_name": "model.decoder.layers.1.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.835019649,
      "end_timestamp": 3191211.835054349,
      "duration_time": 3.4700147807598114e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005725560077529125
    },
    {
      "iter": 2,
      "ops_idx": 14,
      "module_name": "model.decoder.layers.1.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.835140726,
      "end_timestamp": 3191211.835209765,
      "duration_time": 6.903894245624542e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0027397174302571554,
      "memory_efficiency": 0.07418236005732957
    },
    {
      "iter": 2,
      "ops_idx": 15,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191211.835382007,
      "end_timestamp": 3191211.835399115,
      "duration_time": 1.7107930034399033e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.001034972517946077
    },
    {
      "iter": 2,
      "ops_idx": 16,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191211.865299079,
      "end_timestamp": 3191211.865339038,
      "duration_time": 3.9958860725164413e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.492635404552238e-05,
      "memory_efficiency": 0.0024515009160853978
    },
    {
      "iter": 2,
      "ops_idx": 17,
      "module_name": "model.decoder.layers.1.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.835324197,
      "end_timestamp": 3191211.895530751,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 18,
      "module_name": "model.decoder.layers.1.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.895713359,
      "end_timestamp": 3191211.895784279,
      "duration_time": 7.091974839568138e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008890198583267692,
      "memory_efficiency": 0.02415468211473459
    },
    {
      "iter": 2,
      "ops_idx": 19,
      "module_name": "model.decoder.layers.1.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.895900725,
      "end_timestamp": 3191211.895938505,
      "duration_time": 3.77800315618515e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.000525880399666365
    },
    {
      "iter": 2,
      "ops_idx": 20,
      "module_name": "model.decoder.layers.1.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.896029417,
      "end_timestamp": 3191211.896092042,
      "duration_time": 6.262492388486862e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.00402709086160072,
      "memory_efficiency": 0.10899311517521187
    },
    {
      "iter": 2,
      "ops_idx": 21,
      "module_name": "model.decoder.layers.1.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.896197506,
      "end_timestamp": 3191211.896221053,
      "duration_time": 2.3546628654003143e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003000046835913919
    },
    {
      "iter": 2,
      "ops_idx": 22,
      "module_name": "model.decoder.layers.1.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.896318428,
      "end_timestamp": 3191211.896384335,
      "duration_time": 6.590690463781357e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0038265529244791673,
      "memory_efficiency": 0.10356556083664381
    },
    {
      "iter": 2,
      "ops_idx": 23,
      "module_name": "model.decoder.layers.2.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.896508674,
      "end_timestamp": 3191211.896541571,
      "duration_time": 3.289664164185524e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0006039454821393096
    },
    {
      "iter": 2,
      "ops_idx": 24,
      "module_name": "model.decoder.layers.2.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.89662213,
      "end_timestamp": 3191211.896683175,
      "duration_time": 6.104493513703346e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.003098491194876354,
      "memory_efficiency": 0.08389675041458876
    },
    {
      "iter": 2,
      "ops_idx": 25,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191211.896851498,
      "end_timestamp": 3191211.896870754,
      "duration_time": 1.9256025552749634e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0009195167183406104
    },
    {
      "iter": 2,
      "ops_idx": 26,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191211.927104802,
      "end_timestamp": 3191211.92714502,
      "duration_time": 4.0218234062194824e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.4701108825031504e-05,
      "memory_efficiency": 0.002435690824265979
    },
    {
      "iter": 2,
      "ops_idx": 27,
      "module_name": "model.decoder.layers.2.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.89679624,
      "end_timestamp": 3191211.95738198,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 28,
      "module_name": "model.decoder.layers.2.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.957565997,
      "end_timestamp": 3191211.957635713,
      "duration_time": 6.971601396799088e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0009043699013005372,
      "memory_efficiency": 0.024571742999265022
    },
    {
      "iter": 2,
      "ops_idx": 29,
      "module_name": "model.decoder.layers.2.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.957746805,
      "end_timestamp": 3191211.957780626,
      "duration_time": 3.38209792971611e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005874394683427169
    },
    {
      "iter": 2,
      "ops_idx": 30,
      "module_name": "model.decoder.layers.2.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.957859934,
      "end_timestamp": 3191211.957919167,
      "duration_time": 5.923304706811905e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0042576951747082155,
      "memory_efficiency": 0.11523441524074735
    },
    {
      "iter": 2,
      "ops_idx": 31,
      "module_name": "model.decoder.layers.2.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.958015555,
      "end_timestamp": 3191211.958040923,
      "duration_time": 2.536782994866371e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.002784668177484502
    },
    {
      "iter": 2,
      "ops_idx": 32,
      "module_name": "model.decoder.layers.2.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.958142998,
      "end_timestamp": 3191211.958206272,
      "duration_time": 6.327405571937561e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.003985776726620801,
      "memory_efficiency": 0.1078749491275651
    },
    {
      "iter": 2,
      "ops_idx": 33,
      "module_name": "model.decoder.layers.3.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.958336207,
      "end_timestamp": 3191211.958369646,
      "duration_time": 3.3439137041568756e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005941474528022773
    },
    {
      "iter": 2,
      "ops_idx": 34,
      "module_name": "model.decoder.layers.3.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191211.958449889,
      "end_timestamp": 3191211.958509506,
      "duration_time": 5.9617217630147934e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0031726940896055194,
      "memory_efficiency": 0.0859059159560068
    },
    {
      "iter": 2,
      "ops_idx": 35,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191211.958671517,
      "end_timestamp": 3191211.958687925,
      "duration_time": 1.6407575458288193e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010791501443684099
    },
    {
      "iter": 2,
      "ops_idx": 36,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191211.988728005,
      "end_timestamp": 3191211.988766788,
      "duration_time": 3.878306597471237e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.5985224011242236e-05,
      "memory_efficiency": 0.0025258236091324363
    },
    {
      "iter": 2,
      "ops_idx": 37,
      "module_name": "model.decoder.layers.3.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191211.958617435,
      "end_timestamp": 3191212.018798504,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 38,
      "module_name": "model.decoder.layers.3.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.018986302,
      "end_timestamp": 3191212.019059763,
      "duration_time": 7.346086204051971e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008582674218622976,
      "memory_efficiency": 0.023319137981388748
    },
    {
      "iter": 2,
      "ops_idx": 39,
      "module_name": "model.decoder.layers.3.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.019173287,
      "end_timestamp": 3191212.019208899,
      "duration_time": 3.561191260814667e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005578969687971589
    },
    {
      "iter": 2,
      "ops_idx": 40,
      "module_name": "model.decoder.layers.3.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.019283486,
      "end_timestamp": 3191212.019344677,
      "duration_time": 6.119115278124809e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004121449706737346,
      "memory_efficiency": 0.11154693499930403
    },
    {
      "iter": 2,
      "ops_idx": 41,
      "module_name": "model.decoder.layers.3.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.019446548,
      "end_timestamp": 3191212.019469426,
      "duration_time": 2.287793904542923e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003087733936593186
    },
    {
      "iter": 2,
      "ops_idx": 42,
      "module_name": "model.decoder.layers.3.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.019571169,
      "end_timestamp": 3191212.01963618,
      "duration_time": 6.501097232103348e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0038792875984043724,
      "memory_efficiency": 0.1049928234901049
    },
    {
      "iter": 2,
      "ops_idx": 43,
      "module_name": "model.decoder.layers.4.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.019761104,
      "end_timestamp": 3191212.019793929,
      "duration_time": 3.282492980360985e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0006052649073744383
    },
    {
      "iter": 2,
      "ops_idx": 44,
      "module_name": "model.decoder.layers.4.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.019874384,
      "end_timestamp": 3191212.01993577,
      "duration_time": 6.138579919934273e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.003081285842669644,
      "memory_efficiency": 0.08343088717693672
    },
    {
      "iter": 2,
      "ops_idx": 45,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191212.020115052,
      "end_timestamp": 3191212.02013243,
      "duration_time": 1.737801358103752e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010188873050408886
    },
    {
      "iter": 2,
      "ops_idx": 46,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191212.050157121,
      "end_timestamp": 3191212.050196487,
      "duration_time": 3.936607390642166e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.5452286155342225e-05,
      "memory_efficiency": 0.002488416393931771
    },
    {
      "iter": 2,
      "ops_idx": 47,
      "module_name": "model.decoder.layers.4.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.020055855,
      "end_timestamp": 3191212.080362133,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 48,
      "module_name": "model.decoder.layers.4.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.080555762,
      "end_timestamp": 3191212.080626745,
      "duration_time": 7.098261266946793e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008882325163894447,
      "memory_efficiency": 0.024133290023170443
    },
    {
      "iter": 2,
      "ops_idx": 49,
      "module_name": "model.decoder.layers.4.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.080737487,
      "end_timestamp": 3191212.080771583,
      "duration_time": 3.4096185117959976e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005826979771613544
    },
    {
      "iter": 2,
      "ops_idx": 50,
      "module_name": "model.decoder.layers.4.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.080845155,
      "end_timestamp": 3191212.080903457,
      "duration_time": 5.830219015479088e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004325673838592003,
      "memory_efficiency": 0.11707425610770944
    },
    {
      "iter": 2,
      "ops_idx": 51,
      "module_name": "model.decoder.layers.4.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.081007636,
      "end_timestamp": 3191212.081030705,
      "duration_time": 2.3068860173225403e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003062179416730384
    },
    {
      "iter": 2,
      "ops_idx": 52,
      "module_name": "model.decoder.layers.4.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.08112958,
      "end_timestamp": 3191212.081193531,
      "duration_time": 6.395112723112106e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.003943578004086639,
      "memory_efficiency": 0.10673284173950766
    },
    {
      "iter": 2,
      "ops_idx": 53,
      "module_name": "model.decoder.layers.5.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.081332949,
      "end_timestamp": 3191212.081368284,
      "duration_time": 3.533484414219856e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005622715644987748
    },
    {
      "iter": 2,
      "ops_idx": 54,
      "module_name": "model.decoder.layers.5.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.081452807,
      "end_timestamp": 3191212.081517688,
      "duration_time": 6.488105282187462e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0029152916882095575,
      "memory_efficiency": 0.07893632215443572
    },
    {
      "iter": 2,
      "ops_idx": 55,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191212.081680842,
      "end_timestamp": 3191212.081697286,
      "duration_time": 1.6443897038698196e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010767664978002696
    },
    {
      "iter": 2,
      "ops_idx": 56,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191212.111817352,
      "end_timestamp": 3191212.111856845,
      "duration_time": 3.9493199437856674e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.5338168008870555e-05,
      "memory_efficiency": 0.0024804063754725694
    },
    {
      "iter": 2,
      "ops_idx": 57,
      "module_name": "model.decoder.layers.5.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.081627006,
      "end_timestamp": 3191212.141990557,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 58,
      "module_name": "model.decoder.layers.5.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.142179117,
      "end_timestamp": 3191212.142251798,
      "duration_time": 7.268087938427925e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008674780107976539,
      "memory_efficiency": 0.02356938981293023
    },
    {
      "iter": 2,
      "ops_idx": 59,
      "module_name": "model.decoder.layers.5.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.142370045,
      "end_timestamp": 3191212.142405983,
      "duration_time": 3.5937875509262085e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005528367443989262
    },
    {
      "iter": 2,
      "ops_idx": 60,
      "module_name": "model.decoder.layers.5.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.142488751,
      "end_timestamp": 3191212.142549942,
      "duration_time": 6.119068711996078e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004121481070980279,
      "memory_efficiency": 0.11154778387176799
    },
    {
      "iter": 2,
      "ops_idx": 61,
      "module_name": "model.decoder.layers.5.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.142649805,
      "end_timestamp": 3191212.142672976,
      "duration_time": 2.3170839995145798e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003048702110267956
    },
    {
      "iter": 2,
      "ops_idx": 62,
      "module_name": "model.decoder.layers.5.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.142775135,
      "end_timestamp": 3191212.142839484,
      "duration_time": 6.434880197048187e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.003919206744530889,
      "memory_efficiency": 0.10607323419872597
    },
    {
      "iter": 2,
      "ops_idx": 63,
      "module_name": "model.decoder.layers.6.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.142963406,
      "end_timestamp": 3191212.142997816,
      "duration_time": 3.441004082560539e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005773831596959406
    },
    {
      "iter": 2,
      "ops_idx": 64,
      "module_name": "model.decoder.layers.6.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.143079687,
      "end_timestamp": 3191212.143139083,
      "duration_time": 5.939602851867676e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.003184509111655841,
      "memory_efficiency": 0.08622582713010916
    },
    {
      "iter": 2,
      "ops_idx": 65,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191212.143307522,
      "end_timestamp": 3191212.143324204,
      "duration_time": 1.668184995651245e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010614073061863813
    },
    {
      "iter": 2,
      "ops_idx": 66,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191212.173337469,
      "end_timestamp": 3191212.173377183,
      "duration_time": 3.971392288804054e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.5141764284461756e-05,
      "memory_efficiency": 0.0024666206848825006
    },
    {
      "iter": 2,
      "ops_idx": 67,
      "module_name": "model.decoder.layers.6.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.143250646,
      "end_timestamp": 3191212.203342295,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 68,
      "module_name": "model.decoder.layers.6.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.203527593,
      "end_timestamp": 3191212.203598722,
      "duration_time": 7.112883031368256e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.000886406600435414,
      "memory_efficiency": 0.024083679860894828
    },
    {
      "iter": 2,
      "ops_idx": 69,
      "module_name": "model.decoder.layers.6.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.203711736,
      "end_timestamp": 3191212.203745466,
      "duration_time": 3.373017534613609e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005890208957787192
    },
    {
      "iter": 2,
      "ops_idx": 70,
      "module_name": "model.decoder.layers.6.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.203826105,
      "end_timestamp": 3191212.203889341,
      "duration_time": 6.323587149381638e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.003988183490281407,
      "memory_efficiency": 0.10794008812687628
    },
    {
      "iter": 2,
      "ops_idx": 71,
      "module_name": "model.decoder.layers.6.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.203985941,
      "end_timestamp": 3191212.204023753,
      "duration_time": 3.781169652938843e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0018682311367589069
    },
    {
      "iter": 2,
      "ops_idx": 72,
      "module_name": "model.decoder.layers.6.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.204129731,
      "end_timestamp": 3191212.204196279,
      "duration_time": 6.654812023043633e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.003789682680921934,
      "memory_efficiency": 0.10256766860111219
    },
    {
      "iter": 2,
      "ops_idx": 73,
      "module_name": "model.decoder.layers.7.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.204317139,
      "end_timestamp": 3191212.204350592,
      "duration_time": 3.345310688018799e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005938993400018309
    },
    {
      "iter": 2,
      "ops_idx": 74,
      "module_name": "model.decoder.layers.7.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.204433679,
      "end_timestamp": 3191212.204495562,
      "duration_time": 6.188265979290009e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0030565459637143383,
      "memory_efficiency": 0.08276101422282518
    },
    {
      "iter": 2,
      "ops_idx": 75,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191212.204656529,
      "end_timestamp": 3191212.204672637,
      "duration_time": 1.6108155250549316e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.001099209509043158
    },
    {
      "iter": 2,
      "ops_idx": 76,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191212.234732532,
      "end_timestamp": 3191212.234771951,
      "duration_time": 3.9419159293174744e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.540454291688703e-05,
      "memory_efficiency": 0.0024850652685134912
    },
    {
      "iter": 2,
      "ops_idx": 77,
      "module_name": "model.decoder.layers.7.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.204600053,
      "end_timestamp": 3191212.264854369,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 78,
      "module_name": "model.decoder.layers.7.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.265040435,
      "end_timestamp": 3191212.265110023,
      "duration_time": 6.958795711398125e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0009060341370278751,
      "memory_efficiency": 0.02461696030749646
    },
    {
      "iter": 2,
      "ops_idx": 79,
      "module_name": "model.decoder.layers.7.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.265220463,
      "end_timestamp": 3191212.265253564,
      "duration_time": 3.310106694698334e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0006002156404497711
    },
    {
      "iter": 2,
      "ops_idx": 80,
      "module_name": "model.decoder.layers.7.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.265329128,
      "end_timestamp": 3191212.265389163,
      "duration_time": 6.0034915804862976e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004200826390844486,
      "memory_efficiency": 0.11369526300342483
    },
    {
      "iter": 2,
      "ops_idx": 81,
      "module_name": "model.decoder.layers.7.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.265489056,
      "end_timestamp": 3191212.265514538,
      "duration_time": 2.5482382625341415e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.002772150070442469
    },
    {
      "iter": 2,
      "ops_idx": 82,
      "module_name": "model.decoder.layers.7.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.265610705,
      "end_timestamp": 3191212.265682871,
      "duration_time": 7.216585800051689e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.003494675538720661,
      "memory_efficiency": 0.09458330754930501
    },
    {
      "iter": 2,
      "ops_idx": 83,
      "module_name": "model.decoder.layers.8.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.265804073,
      "end_timestamp": 3191212.265837293,
      "duration_time": 3.322027623653412e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005980617968283085
    },
    {
      "iter": 2,
      "ops_idx": 84,
      "module_name": "model.decoder.layers.8.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.265923467,
      "end_timestamp": 3191212.265984876,
      "duration_time": 6.140908226370811e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0030801175826345086,
      "memory_efficiency": 0.08339925461307816
    },
    {
      "iter": 2,
      "ops_idx": 85,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191212.266157324,
      "end_timestamp": 3191212.266174276,
      "duration_time": 1.695193350315094e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010444966305027173
    },
    {
      "iter": 2,
      "ops_idx": 86,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191212.296263222,
      "end_timestamp": 3191212.296302654,
      "duration_time": 3.943173214793205e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.5393254136212296e-05,
      "memory_efficiency": 0.002484272902492992
    },
    {
      "iter": 2,
      "ops_idx": 87,
      "module_name": "model.decoder.layers.8.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.266102021,
      "end_timestamp": 3191212.326155264,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 88,
      "module_name": "model.decoder.layers.8.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.326348671,
      "end_timestamp": 3191212.326427936,
      "duration_time": 7.926486432552338e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0007954226025338304,
      "memory_efficiency": 0.021611643352085323
    },
    {
      "iter": 2,
      "ops_idx": 89,
      "module_name": "model.decoder.layers.8.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.326543042,
      "end_timestamp": 3191212.326576299,
      "duration_time": 3.325706347823143e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005974002518339871
    },
    {
      "iter": 2,
      "ops_idx": 90,
      "module_name": "model.decoder.layers.8.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.326701306,
      "end_timestamp": 3191212.326764002,
      "duration_time": 6.26961700618267e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004022514587996305,
      "memory_efficiency": 0.1088692584426024
    },
    {
      "iter": 2,
      "ops_idx": 91,
      "module_name": "model.decoder.layers.8.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.32686484,
      "end_timestamp": 3191212.32688762,
      "duration_time": 2.2780150175094604e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.003100988722502519
    },
    {
      "iter": 2,
      "ops_idx": 92,
      "module_name": "model.decoder.layers.8.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.326984181,
      "end_timestamp": 3191212.327063442,
      "duration_time": 7.926113903522491e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0031818399502575286,
      "memory_efficiency": 0.08611642003767975
    },
    {
      "iter": 2,
      "ops_idx": 93,
      "module_name": "model.decoder.layers.9.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.327195833,
      "end_timestamp": 3191212.327229784,
      "duration_time": 3.395089879631996e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005851915207413561
    },
    {
      "iter": 2,
      "ops_idx": 94,
      "module_name": "model.decoder.layers.9.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.327314323,
      "end_timestamp": 3191212.327374653,
      "duration_time": 6.033014506101608e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0031352020424051455,
      "memory_efficiency": 0.08489075705166553
    },
    {
      "iter": 2,
      "ops_idx": 95,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191212.32754238,
      "end_timestamp": 3191212.327558764,
      "duration_time": 1.6383826732635498e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.001080714396794592
    },
    {
      "iter": 2,
      "ops_idx": 96,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191212.357581853,
      "end_timestamp": 3191212.357620952,
      "duration_time": 3.909924998879433e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.5694222199729896e-05,
      "memory_efficiency": 0.002505398024298268
    },
    {
      "iter": 2,
      "ops_idx": 97,
      "module_name": "model.decoder.layers.9.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.327482944,
      "end_timestamp": 3191212.387852779,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 98,
      "module_name": "model.decoder.layers.9.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.388047424,
      "end_timestamp": 3191212.388121771,
      "duration_time": 7.434701547026634e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.000848037601408681,
      "memory_efficiency": 0.023041193615091937
    },
    {
      "iter": 2,
      "ops_idx": 99,
      "module_name": "model.decoder.layers.9.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.388236566,
      "end_timestamp": 3191212.388272019,
      "duration_time": 3.545312210917473e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005603957258255931
    },
    {
      "iter": 2,
      "ops_idx": 100,
      "module_name": "model.decoder.layers.9.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.388348456,
      "end_timestamp": 3191212.388409076,
      "duration_time": 6.0619786381721497e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.00416029606401317,
      "memory_efficiency": 0.11259831070405242
    },
    {
      "iter": 2,
      "ops_idx": 101,
      "module_name": "model.decoder.layers.9.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.388513996,
      "end_timestamp": 3191212.388537772,
      "duration_time": 2.377619966864586e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.002971079893942757
    },
    {
      "iter": 2,
      "ops_idx": 102,
      "module_name": "model.decoder.layers.9.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.388632537,
      "end_timestamp": 3191212.388698946,
      "duration_time": 6.640935316681862e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0037976014922428843,
      "memory_efficiency": 0.10278199103485337
    },
    {
      "iter": 2,
      "ops_idx": 103,
      "module_name": "model.decoder.layers.10.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.388825046,
      "end_timestamp": 3191212.388859214,
      "duration_time": 3.416789695620537e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.000581475006279135
    },
    {
      "iter": 2,
      "ops_idx": 104,
      "module_name": "model.decoder.layers.10.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.388941106,
      "end_timestamp": 3191212.389000532,
      "duration_time": 5.942629650235176e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0031828871248338847,
      "memory_efficiency": 0.08618190916648788
    },
    {
      "iter": 2,
      "ops_idx": 105,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191212.389172432,
      "end_timestamp": 3191212.389188764,
      "duration_time": 1.633213832974434e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.00108413467159413
    },
    {
      "iter": 2,
      "ops_idx": 106,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191212.419206028,
      "end_timestamp": 3191212.419244588,
      "duration_time": 3.8560014218091965e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.6193381803474596e-05,
      "memory_efficiency": 0.0025404343245160927
    },
    {
      "iter": 2,
      "ops_idx": 107,
      "module_name": "model.decoder.layers.10.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.389116219,
      "end_timestamp": 3191212.449311285,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 108,
      "module_name": "model.decoder.layers.10.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.449499703,
      "end_timestamp": 3191212.449571245,
      "duration_time": 7.154187187552452e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0008812889992730082,
      "memory_efficiency": 0.02394463456498821
    },
    {
      "iter": 2,
      "ops_idx": 109,
      "module_name": "model.decoder.layers.10.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.449683229,
      "end_timestamp": 3191212.449718212,
      "duration_time": 3.498280420899391e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.000567929831424047
    },
    {
      "iter": 2,
      "ops_idx": 110,
      "module_name": "model.decoder.layers.10.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.449792692,
      "end_timestamp": 3191212.449851935,
      "duration_time": 5.924282595515251e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0042569923804126174,
      "memory_efficiency": 0.11521539413041308
    },
    {
      "iter": 2,
      "ops_idx": 111,
      "module_name": "model.decoder.layers.10.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.449953946,
      "end_timestamp": 3191212.449977009,
      "duration_time": 2.306327223777771e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0030629213435798583
    },
    {
      "iter": 2,
      "ops_idx": 112,
      "module_name": "model.decoder.layers.10.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.45008036,
      "end_timestamp": 3191212.450145336,
      "duration_time": 6.49760477244854e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.0038813727137509187,
      "memory_efficiency": 0.10504925708570283
    },
    {
      "iter": 2,
      "ops_idx": 113,
      "module_name": "model.decoder.layers.11.self_attn_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.450264618,
      "end_timestamp": 3191212.450298552,
      "duration_time": 3.393413498997688e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005854806112789583
    },
    {
      "iter": 2,
      "ops_idx": 114,
      "module_name": "model.decoder.layers.11.self_attn.qkv_proj",
      "operator_name": "QKVParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          2304
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.450380899,
      "end_timestamp": 3191212.450440681,
      "duration_time": 5.9782061725854874e-05,
      "ops_type": "TensorCore",
      "computes_ops": 28311552.0,
      "memory_byte": 3563520.0,
      "computes_efficiency": 0.0031639456477977725,
      "memory_efficiency": 0.08566903749074772
    },
    {
      "iter": 2,
      "ops_idx": 115,
      "module_name": "reshape_and_cache_flash",
      "operator_name": "reshape_and_cache_flash",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4
        ],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int64",
        "str",
        "torch.float32",
        "torch.float32"
      ],
      "output_shapes": [
        []
      ],
      "output_dtypes": [
        "NoneType"
      ],
      "start_timestamp": 3191212.450605946,
      "end_timestamp": 3191212.450622475,
      "duration_time": 1.6528647392988205e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 12320.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0010712453961634293
    },
    {
      "iter": 2,
      "ops_idx": 116,
      "module_name": "varlen_fwd",
      "operator_name": "varlen_fwd",
      "input_shapes": [
        [
          4,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          1054,
          16,
          12,
          64
        ],
        [
          4,
          12,
          64
        ],
        [
          5
        ],
        [
          5
        ],
        [
          4
        ],
        [],
        [
          4,
          128
        ],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        [],
        []
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.float16",
        "torch.int32",
        "torch.int32",
        "torch.int32",
        "NoneType",
        "torch.int32",
        "NoneType",
        "int",
        "int",
        "float",
        "float",
        "bool",
        "bool",
        "int",
        "int",
        "int",
        "bool",
        "NoneType"
      ],
      "output_shapes": [
        [
          4,
          12,
          64
        ],
        [
          12,
          4
        ]
      ],
      "output_dtypes": [
        "torch.float16",
        "torch.float32"
      ],
      "start_timestamp": 3191212.480560815,
      "end_timestamp": 3191212.480600924,
      "duration_time": 4.010926932096481e-05,
      "ops_type": "TensorCore",
      "computes_ops": 208896.0,
      "memory_byte": 68160.0,
      "computes_efficiency": 3.479538123157314e-05,
      "memory_efficiency": 0.002442307858803772
    },
    {
      "iter": 2,
      "ops_idx": 117,
      "module_name": "model.decoder.layers.11.self_attn.attn",
      "operator_name": "Attention",
      "input_shapes": [
        [
          4,
          768
        ],
        [
          4,
          768
        ],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16",
        "torch.float16",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.450547979,
      "end_timestamp": 3191212.510542904,
      "duration_time": 1e-11,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 0.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0
    },
    {
      "iter": 2,
      "ops_idx": 118,
      "module_name": "model.decoder.layers.11.self_attn.out_proj",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.510727652,
      "end_timestamp": 3191212.510797249,
      "duration_time": 6.95972703397274e-05,
      "ops_type": "TensorCore",
      "computes_ops": 9437184.0,
      "memory_byte": 1191936.0,
      "computes_efficiency": 0.0009059128951974027,
      "memory_efficiency": 0.024613666165249088
    },
    {
      "iter": 2,
      "ops_idx": 119,
      "module_name": "model.decoder.layers.11.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.510909066,
      "end_timestamp": 3191212.510942719,
      "duration_time": 3.365287557244301e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005903738613476252
    },
    {
      "iter": 2,
      "ops_idx": 120,
      "module_name": "model.decoder.layers.11.fc1",
      "operator_name": "ColumnParallelLinear",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.51101609,
      "end_timestamp": 3191212.511075194,
      "duration_time": 5.9104058891534805e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.004266987131087134,
      "memory_efficiency": 0.11548590181172774
    },
    {
      "iter": 2,
      "ops_idx": 121,
      "module_name": "model.decoder.layers.11.activation_fn",
      "operator_name": "ReLU",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          3072
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.511173902,
      "end_timestamp": 3191212.511196266,
      "duration_time": 2.2363848984241486e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 49152.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0031587133699417656
    },
    {
      "iter": 2,
      "ops_idx": 122,
      "module_name": "model.decoder.layers.11.fc2",
      "operator_name": "RowParallelLinear",
      "input_shapes": [
        [
          4,
          3072
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ],
        []
      ],
      "output_dtypes": [
        "torch.float16",
        "NoneType"
      ],
      "start_timestamp": 3191212.511292076,
      "end_timestamp": 3191212.511356202,
      "duration_time": 6.412575021386147e-05,
      "ops_type": "TensorCore",
      "computes_ops": 37748736.0,
      "memory_byte": 4749312.0,
      "computes_efficiency": 0.003932839114460453,
      "memory_efficiency": 0.10644219395575848
    },
    {
      "iter": 2,
      "ops_idx": 123,
      "module_name": "model.decoder.final_layer_norm",
      "operator_name": "LayerNorm",
      "input_shapes": [
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          768
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.511546345,
      "end_timestamp": 3191212.511581078,
      "duration_time": 3.4733209758996964e-05,
      "ops_type": "ShardCore",
      "computes_ops": 0.0,
      "memory_byte": 13824.0,
      "computes_efficiency": 0.0,
      "memory_efficiency": 0.0005720110014309285
    },
    {
      "iter": 2,
      "ops_idx": 124,
      "module_name": "logits_processor",
      "operator_name": "LogitsProcessor",
      "input_shapes": [
        [],
        [
          4,
          768
        ]
      ],
      "input_dtypes": [
        "VocabParallelEmbedding",
        "torch.float16"
      ],
      "output_shapes": [
        [
          4,
          50272
        ]
      ],
      "output_dtypes": [
        "torch.float16"
      ],
      "start_timestamp": 3191212.511773103,
      "end_timestamp": 3191212.511859837,
      "duration_time": 8.673407137393951e-05,
      "ops_type": "TensorCore",
      "computes_ops": 617742336.0,
      "memory_byte": 77626112.0,
      "computes_efficiency": 0.04758322336576958,
      "memory_efficiency": 1.2862745506943316
    }
  ]
}